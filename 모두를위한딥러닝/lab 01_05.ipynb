{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant(\"Hello, TensorFlow!\")\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0)\n",
    "node3 = tf.add(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: Tensor(\"Const_4:0\", shape=(), dtype=float32) node2: Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "node3:  Tensor(\"Add_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"node1:\", node1, \"node2:\", node2)\n",
    "print(\"node3: \", node3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1, node2):  [3.0, 4.0]\n",
      "sess.run(node3):  7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"sess.run(node1, node2): \", sess.run([node1, node2]) )\n",
    "print(\"sess.run(node3): \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b\n",
    "\n",
    "print(sess.run(adder_node, feed_dict = {a: 3, b: 4.5}))\n",
    "print(sess.run(adder_node, feed_dict = {a: [1,3], b: [2,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab 02 TensorFlow로 간단한 linear regression 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = x_train*W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17.420603 [-0.68606687] [-0.56809336]\n",
      "20 0.16067691 [0.78456527] [0.07068123]\n",
      "40 0.0039356058 [0.92717737] [0.12564096]\n",
      "60 0.0022869457 [0.94321513] [0.12528582]\n",
      "80 0.0020653685 [0.947085] [0.11992629]\n",
      "100 0.0018756945 [0.94968617] [0.11434054]\n",
      "120 0.0017035339 [0.9520617] [0.10897176]\n",
      "140 0.0015471826 [0.95431566] [0.10385094]\n",
      "160 0.0014051736 [0.9564627] [0.09897039]\n",
      "180 0.0012762047 [0.95850885] [0.09431915]\n",
      "200 0.0011590678 [0.96045876] [0.0898865]\n",
      "220 0.0010526829 [0.96231705] [0.08566217]\n",
      "240 0.0009560634 [0.96408796] [0.08163638]\n",
      "260 0.0008683132 [0.9657757] [0.07779981]\n",
      "280 0.00078861736 [0.96738416] [0.07414352]\n",
      "300 0.00071622996 [0.968917] [0.07065907]\n",
      "320 0.00065049704 [0.9703778] [0.0673383]\n",
      "340 0.0005907851 [0.9717699] [0.06417361]\n",
      "360 0.00053656317 [0.97309667] [0.06115768]\n",
      "380 0.00048731422 [0.974361] [0.05828348]\n",
      "400 0.00044258704 [0.97556597] [0.05554436]\n",
      "420 0.00040196444 [0.97671425] [0.05293397]\n",
      "440 0.00036506995 [0.9778086] [0.05044628]\n",
      "460 0.00033156367 [0.97885144] [0.04807552]\n",
      "480 0.00030112918 [0.9798456] [0.0458161]\n",
      "500 0.0002734905 [0.98079264] [0.04366283]\n",
      "520 0.0002483904 [0.98169535] [0.04161083]\n",
      "540 0.00022559195 [0.98255557] [0.03965528]\n",
      "560 0.00020488491 [0.98337543] [0.03779162]\n",
      "580 0.00018607856 [0.9841567] [0.03601553]\n",
      "600 0.00016900129 [0.9849012] [0.03432295]\n",
      "620 0.0001534897 [0.9856109] [0.0327099]\n",
      "640 0.00013940093 [0.98628706] [0.03117265]\n",
      "660 0.00012660662 [0.98693156] [0.02970766]\n",
      "680 0.000114985975 [0.9875457] [0.02831152]\n",
      "700 0.00010443353 [0.988131] [0.02698098]\n",
      "720 9.484686e-05 [0.98868877] [0.02571299]\n",
      "740 8.614224e-05 [0.9892203] [0.02450461]\n",
      "760 7.823573e-05 [0.9897269] [0.02335301]\n",
      "780 7.105515e-05 [0.9902099] [0.02225552]\n",
      "800 6.453299e-05 [0.99066997] [0.02120952]\n",
      "820 5.8610254e-05 [0.99110836] [0.02021272]\n",
      "840 5.3229716e-05 [0.99152625] [0.01926281]\n",
      "860 4.834481e-05 [0.99192446] [0.01835752]\n",
      "880 4.3907985e-05 [0.992304] [0.01749478]\n",
      "900 3.9877563e-05 [0.9926657] [0.0166726]\n",
      "920 3.6217996e-05 [0.9930104] [0.01588905]\n",
      "940 3.2893233e-05 [0.9933389] [0.01514231]\n",
      "960 2.9873006e-05 [0.993652] [0.01443066]\n",
      "980 2.7132022e-05 [0.9939503] [0.01375245]\n",
      "1000 2.464183e-05 [0.99423456] [0.01310614]\n",
      "1020 2.2379425e-05 [0.9945055] [0.01249021]\n",
      "1040 2.0325971e-05 [0.99476373] [0.01190322]\n",
      "1060 1.8460274e-05 [0.9950099] [0.01134379]\n",
      "1080 1.6766164e-05 [0.9952444] [0.01081066]\n",
      "1100 1.522701e-05 [0.9954679] [0.01030259]\n",
      "1120 1.382931e-05 [0.99568087] [0.0098184]\n",
      "1140 1.2560286e-05 [0.9958838] [0.00935697]\n",
      "1160 1.140694e-05 [0.9960773] [0.00891724]\n",
      "1180 1.0360333e-05 [0.9962616] [0.00849817]\n",
      "1200 9.409207e-06 [0.9964373] [0.00809878]\n",
      "1220 8.545965e-06 [0.9966048] [0.00771816]\n",
      "1240 7.761265e-06 [0.99676436] [0.0073554]\n",
      "1260 7.0489755e-06 [0.9969165] [0.00700972]\n",
      "1280 6.401653e-06 [0.9970614] [0.00668027]\n",
      "1300 5.8145665e-06 [0.9971994] [0.00636631]\n",
      "1320 5.281004e-06 [0.997331] [0.00606714]\n",
      "1340 4.795897e-06 [0.9974565] [0.00578201]\n",
      "1360 4.355586e-06 [0.99757606] [0.00551027]\n",
      "1380 3.9558126e-06 [0.99768996] [0.00525129]\n",
      "1400 3.5929631e-06 [0.9977985] [0.0050045]\n",
      "1420 3.263056e-06 [0.997902] [0.0047693]\n",
      "1440 2.9636076e-06 [0.99800056] [0.00454517]\n",
      "1460 2.6916885e-06 [0.9980945] [0.00433158]\n",
      "1480 2.4447256e-06 [0.9981841] [0.00412802]\n",
      "1500 2.2200738e-06 [0.9982694] [0.00393403]\n",
      "1520 2.016412e-06 [0.99835074] [0.00374917]\n",
      "1540 1.8315651e-06 [0.9984282] [0.00357301]\n",
      "1560 1.6633985e-06 [0.99850214] [0.00340509]\n",
      "1580 1.5106224e-06 [0.9985725] [0.00324505]\n",
      "1600 1.3719787e-06 [0.9986396] [0.00309254]\n",
      "1620 1.246099e-06 [0.99870354] [0.0029472]\n",
      "1640 1.1317057e-06 [0.9987644] [0.00280869]\n",
      "1660 1.0278078e-06 [0.9988225] [0.00267672]\n",
      "1680 9.335601e-07 [0.9988778] [0.00255094]\n",
      "1700 8.477958e-07 [0.9989305] [0.00243108]\n",
      "1720 7.6998793e-07 [0.99898076] [0.00231685]\n",
      "1740 6.994294e-07 [0.9990286] [0.002208]\n",
      "1760 6.3520747e-07 [0.9990743] [0.00210427]\n",
      "1780 5.7699367e-07 [0.9991178] [0.00200542]\n",
      "1800 5.240409e-07 [0.9991592] [0.00191118]\n",
      "1820 4.759438e-07 [0.99919873] [0.00182139]\n",
      "1840 4.322059e-07 [0.99923635] [0.00173583]\n",
      "1860 3.9259248e-07 [0.9992722] [0.00165429]\n",
      "1880 3.565896e-07 [0.9993064] [0.00157659]\n",
      "1900 3.2390662e-07 [0.999339] [0.00150254]\n",
      "1920 2.9417637e-07 [0.99937004] [0.00143196]\n",
      "1940 2.6720292e-07 [0.9993996] [0.00136469]\n",
      "1960 2.4266598e-07 [0.9994278] [0.00130059]\n",
      "1980 2.2040848e-07 [0.9994547] [0.00123949]\n",
      "2000 2.0013276e-07 [0.9994803] [0.00118126]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step%20==0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.0013276e-07 [0.99948156] [0.00117842]\n",
      "20 1.8182506e-07 [0.9995058] [0.00112308]\n",
      "40 1.6518585e-07 [0.999529] [0.00107036]\n",
      "60 1.5003332e-07 [0.9995511] [0.00102012]\n",
      "80 1.3627489e-07 [0.9995722] [0.00097223]\n",
      "100 1.2374132e-07 [0.99959236] [0.00092661]\n",
      "120 1.1241914e-07 [0.99961144] [0.00088315]\n",
      "140 1.02133065e-07 [0.9996296] [0.00084169]\n",
      "160 9.273612e-08 [0.999647] [0.00080216]\n",
      "180 8.427921e-08 [0.9996637] [0.00076455]\n",
      "200 7.65327e-08 [0.9996793] [0.00072867]\n",
      "220 6.950872e-08 [0.9996944] [0.00069445]\n",
      "240 6.315771e-08 [0.9997087] [0.00066193]\n",
      "260 5.7390043e-08 [0.99972236] [0.00063086]\n",
      "280 5.2124303e-08 [0.9997355] [0.0006013]\n",
      "300 4.738017e-08 [0.99974775] [0.00057307]\n",
      "320 4.302221e-08 [0.9997597] [0.00054625]\n",
      "340 3.9068393e-08 [0.9997709] [0.00052058]\n",
      "360 3.551359e-08 [0.9997816] [0.00049623]\n",
      "380 3.223968e-08 [0.9997919] [0.00047292]\n",
      "400 2.9319338e-08 [0.9998015] [0.00045081]\n",
      "420 2.6619494e-08 [0.99981105] [0.0004297]\n",
      "440 2.4164763e-08 [0.99981976] [0.00040951]\n",
      "460 2.1984127e-08 [0.9998281] [0.0003904]\n",
      "480 1.9966905e-08 [0.9998364] [0.00037209]\n",
      "500 1.8135966e-08 [0.9998439] [0.00035461]\n",
      "520 1.6498756e-08 [0.99985105] [0.0003381]\n",
      "540 1.4984744e-08 [0.9998582] [0.00032232]\n",
      "560 1.3614218e-08 [0.9998649] [0.00030715]\n",
      "580 1.2366377e-08 [0.999871] [0.00029278]\n",
      "600 1.1234341e-08 [0.99987704] [0.00027917]\n",
      "620 1.0203196e-08 [0.999883] [0.0002661]\n",
      "640 9.26688e-09 [0.9998885] [0.00025354]\n",
      "660 8.422581e-09 [0.9998936] [0.00024167]\n",
      "680 7.65609e-09 [0.99989843] [0.00023043]\n",
      "700 6.9651755e-09 [0.9999032] [0.00021975]\n",
      "720 6.3150103e-09 [0.999908] [0.00020944]\n",
      "740 5.739764e-09 [0.99991226] [0.00019954]\n",
      "760 5.208989e-09 [0.99991626] [0.00019017]\n",
      "780 4.7444417e-09 [0.99992007] [0.00018132]\n",
      "800 4.312034e-09 [0.9999237] [0.00017294]\n",
      "820 3.918464e-09 [0.9999273] [0.00016497]\n",
      "840 3.5643002e-09 [0.99993086] [0.00015726]\n",
      "860 3.2346665e-09 [0.9999342] [0.0001498]\n",
      "880 2.9331453e-09 [0.99993724] [0.00014271]\n",
      "900 2.6637064e-09 [0.9999401] [0.00013602]\n",
      "920 2.4283746e-09 [0.9999429] [0.00012968]\n",
      "940 2.2082116e-09 [0.99994546] [0.00012367]\n",
      "960 2.0087327e-09 [0.9999479] [0.00011799]\n",
      "980 1.8333234e-09 [0.9999503] [0.0001126]\n",
      "1000 1.6606521e-09 [0.9999527] [0.00010741]\n",
      "1020 1.512935e-09 [0.99995506] [0.00010236]\n",
      "1040 1.365971e-09 [0.9999572] [9.7454365e-05]\n",
      "1060 1.2428482e-09 [0.9999593] [9.280123e-05]\n",
      "1080 1.1239282e-09 [0.99996114] [8.8385714e-05]\n",
      "1100 1.0208758e-09 [0.9999629] [8.421579e-05]\n",
      "1120 9.330327e-10 [0.9999647] [8.027433e-05]\n",
      "1140 8.430116e-10 [0.99996626] [7.6534736e-05]\n",
      "1160 7.675614e-10 [0.99996775] [7.300813e-05]\n",
      "1180 6.9942513e-10 [0.9999692] [6.96683e-05]\n",
      "1200 6.359464e-10 [0.99997056] [6.650846e-05]\n",
      "1220 5.8360783e-10 [0.99997187] [6.3520674e-05]\n",
      "1240 5.330409e-10 [0.9999731] [6.0694234e-05]\n",
      "1260 4.852924e-10 [0.9999743] [5.7986195e-05]\n",
      "1280 4.42243e-10 [0.9999755] [5.5386237e-05]\n",
      "1300 4.0355155e-10 [0.9999767] [5.2858995e-05]\n",
      "1320 3.650591e-10 [0.9999779] [5.0378654e-05]\n",
      "1340 3.2924655e-10 [0.9999791] [4.793129e-05]\n",
      "1360 2.9833794e-10 [0.99998015] [4.5535977e-05]\n",
      "1380 2.685141e-10 [0.9999811] [4.3278556e-05]\n",
      "1400 2.425177e-10 [0.999982] [4.113914e-05]\n",
      "1420 2.2131985e-10 [0.9999829] [3.9118953e-05]\n",
      "1440 2.0130624e-10 [0.9999837] [3.7209225e-05]\n",
      "1460 1.8044943e-10 [0.9999845] [3.539804e-05]\n",
      "1480 1.6299495e-10 [0.9999852] [3.368659e-05]\n",
      "1500 1.4762354e-10 [0.99998593] [3.2065745e-05]\n",
      "1520 1.3561063e-10 [0.99998665] [3.0535895e-05]\n",
      "1540 1.2199071e-10 [0.9999872] [2.9084324e-05]\n",
      "1560 1.09447264e-10 [0.9999878] [2.7716596e-05]\n",
      "1580 1.005939e-10 [0.9999884] [2.6423177e-05]\n",
      "1600 9.1381715e-11 [0.99998885] [2.5196514e-05]\n",
      "1620 8.3092054e-11 [0.9999894] [2.4045748e-05]\n",
      "1640 7.6436635e-11 [0.99998987] [2.2949816e-05]\n",
      "1660 6.939634e-11 [0.9999903] [2.1914288e-05]\n",
      "1680 6.332357e-11 [0.9999907] [2.0944322e-05]\n",
      "1700 5.780147e-11 [0.9999911] [2.0018071e-05]\n",
      "1720 5.3291888e-11 [0.9999915] [1.9145062e-05]\n",
      "1740 4.8805997e-11 [0.99999183] [1.8321327e-05]\n",
      "1760 4.437221e-11 [0.9999922] [1.7543685e-05]\n",
      "1780 4.0293695e-11 [0.9999925] [1.6801807e-05]\n",
      "1800 3.7597186e-11 [0.9999928] [1.6102844e-05]\n",
      "1820 3.465554e-11 [0.9999931] [1.5441628e-05]\n",
      "1840 3.2198244e-11 [0.9999933] [1.4822135e-05]\n",
      "1860 2.936081e-11 [0.99999356] [1.4235229e-05]\n",
      "1880 2.7730115e-11 [0.99999386] [1.3676933e-05]\n",
      "1900 2.549072e-11 [0.99999404] [1.3154398e-05]\n",
      "1920 2.3524885e-11 [0.9999943] [1.2651733e-05]\n",
      "1940 2.1734317e-11 [0.9999945] [1.2179667e-05]\n",
      "1960 2.0425736e-11 [0.9999947] [1.1735016e-05]\n",
      "1980 1.834266e-11 [0.9999948] [1.1313414e-05]\n",
      "2000 1.762146e-11 [0.999995] [1.0922408e-05]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "                feed_dict = {X: [1,2,3], Y:[1,2,3]})\n",
    "    if step %20 ==0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 39.073486 [-0.21399465] [0.2880854]\n",
      "20 0.032028783 [1.1083122] [0.68549436]\n",
      "40 0.027275458 [1.1068323] [0.71419567]\n",
      "60 0.02381984 [1.099861] [0.7394694]\n",
      "80 0.020802012 [1.0933212] [0.7630808]\n",
      "100 0.018166596 [1.0872095] [0.7851458]\n",
      "120 0.015865024 [1.0814981] [0.80576587]\n",
      "140 0.0138550475 [1.0761608] [0.8250355]\n",
      "160 0.012099708 [1.071173] [0.84304315]\n",
      "180 0.010566778 [1.0665118] [0.8598714]\n",
      "200 0.0092280395 [1.0621557] [0.8755976]\n",
      "220 0.008058916 [1.0580852] [0.89029396]\n",
      "240 0.0070379116 [1.0542811] [0.9040277]\n",
      "260 0.00614627 [1.0507262] [0.916862]\n",
      "280 0.0053675813 [1.0474042] [0.92885584]\n",
      "300 0.0046875468 [1.0442996] [0.94006425]\n",
      "320 0.004093668 [1.0413985] [0.9505386]\n",
      "340 0.0035750244 [1.0386871] [0.96032697]\n",
      "360 0.0031220973 [1.0361536] [0.96947426]\n",
      "380 0.0027265437 [1.0337858] [0.9780225]\n",
      "400 0.002381118 [1.031573] [0.9860109]\n",
      "420 0.0020794456 [1.0295054] [0.99347615]\n",
      "440 0.0018159968 [1.0275731] [1.0004525]\n",
      "460 0.0015859182 [1.0257673] [1.0069718]\n",
      "480 0.0013850005 [1.0240797] [1.0130644]\n",
      "500 0.001209539 [1.0225028] [1.0187577]\n",
      "520 0.0010563001 [1.0210291] [1.0240784]\n",
      "540 0.00092245557 [1.0196518] [1.0290508]\n",
      "560 0.0008055929 [1.0183647] [1.0336974]\n",
      "580 0.00070353935 [1.0171621] [1.0380393]\n",
      "600 0.00061439734 [1.0160382] [1.0420972]\n",
      "620 0.0005365631 [1.0149877] [1.0458893]\n",
      "640 0.0004685705 [1.014006] [1.0494336]\n",
      "660 0.00040920725 [1.0130887] [1.0527452]\n",
      "680 0.00035736177 [1.0122316] [1.0558401]\n",
      "700 0.0003120922 [1.0114306] [1.0587318]\n",
      "720 0.00027255382 [1.0106821] [1.0614343]\n",
      "740 0.00023802691 [1.0099823] [1.0639601]\n",
      "760 0.00020786915 [1.0093287] [1.0663203]\n",
      "780 0.00018153226 [1.0087178] [1.0685261]\n",
      "800 0.00015852854 [1.0081466] [1.0705878]\n",
      "820 0.00013844112 [1.0076132] [1.072514]\n",
      "840 0.00012090515 [1.0071146] [1.074314]\n",
      "860 0.00010558638 [1.0066487] [1.075996]\n",
      "880 9.220941e-05 [1.0062133] [1.077568]\n",
      "900 8.05284e-05 [1.0058064] [1.0790373]\n",
      "920 7.0324204e-05 [1.005426] [1.0804102]\n",
      "940 6.1414525e-05 [1.0050707] [1.0816933]\n",
      "960 5.3634205e-05 [1.0047386] [1.0828922]\n",
      "980 4.683721e-05 [1.0044283] [1.0840126]\n",
      "1000 4.090461e-05 [1.0041382] [1.0850595]\n",
      "1020 3.5723006e-05 [1.0038673] [1.0860379]\n",
      "1040 3.1198153e-05 [1.0036141] [1.0869522]\n",
      "1060 2.7245838e-05 [1.0033774] [1.0878066]\n",
      "1080 2.379467e-05 [1.0031562] [1.0886052]\n",
      "1100 2.0779291e-05 [1.0029495] [1.0893512]\n",
      "1120 1.8147057e-05 [1.0027564] [1.0900486]\n",
      "1140 1.5849124e-05 [1.002576] [1.0907001]\n",
      "1160 1.3841616e-05 [1.0024072] [1.0913092]\n",
      "1180 1.2087148e-05 [1.0022496] [1.0918784]\n",
      "1200 1.0556069e-05 [1.0021023] [1.0924102]\n",
      "1220 9.218967e-06 [1.0019646] [1.0929072]\n",
      "1240 8.050325e-06 [1.0018358] [1.0933719]\n",
      "1260 7.0309266e-06 [1.0017157] [1.0938058]\n",
      "1280 6.140086e-06 [1.0016034] [1.0942115]\n",
      "1300 5.362292e-06 [1.0014982] [1.0945907]\n",
      "1320 4.68316e-06 [1.0014002] [1.0949447]\n",
      "1340 4.090158e-06 [1.0013086] [1.0952756]\n",
      "1360 3.572383e-06 [1.001223] [1.095585]\n",
      "1380 3.1193426e-06 [1.0011427] [1.0958741]\n",
      "1400 2.7242668e-06 [1.001068] [1.0961443]\n",
      "1420 2.3791993e-06 [1.000998] [1.0963968]\n",
      "1440 2.0779473e-06 [1.0009327] [1.0966325]\n",
      "1460 1.8144941e-06 [1.0008717] [1.0968531]\n",
      "1480 1.5847849e-06 [1.0008147] [1.0970592]\n",
      "1500 1.384047e-06 [1.0007612] [1.0972517]\n",
      "1520 1.2086244e-06 [1.0007114] [1.0974317]\n",
      "1540 1.055471e-06 [1.0006648] [1.0975999]\n",
      "1560 9.2176936e-07 [1.0006212] [1.097757]\n",
      "1580 8.05135e-07 [1.0005805] [1.0979038]\n",
      "1600 7.031706e-07 [1.0005426] [1.098041]\n",
      "1620 6.1408605e-07 [1.0005071] [1.0981692]\n",
      "1640 5.3635154e-07 [1.0004739] [1.0982891]\n",
      "1660 4.6850855e-07 [1.0004427] [1.0984012]\n",
      "1680 4.091005e-07 [1.0004139] [1.0985057]\n",
      "1700 3.5725134e-07 [1.0003868] [1.0986036]\n",
      "1720 3.1201444e-07 [1.0003616] [1.098695]\n",
      "1740 2.7262712e-07 [1.0003377] [1.0987804]\n",
      "1760 2.3805651e-07 [1.0003158] [1.0988601]\n",
      "1780 2.0785728e-07 [1.000295] [1.0989348]\n",
      "1800 1.8153237e-07 [1.0002759] [1.0990044]\n",
      "1820 1.5849969e-07 [1.0002577] [1.0990696]\n",
      "1840 1.3860222e-07 [1.0002409] [1.0991304]\n",
      "1860 1.2110505e-07 [1.0002252] [1.0991871]\n",
      "1880 1.056967e-07 [1.0002105] [1.0992404]\n",
      "1900 9.233695e-08 [1.0001966] [1.09929]\n",
      "1920 8.065073e-08 [1.0001838] [1.0993365]\n",
      "1940 7.045232e-08 [1.0001718] [1.0993799]\n",
      "1960 6.152501e-08 [1.0001605] [1.0994207]\n",
      "1980 5.3753695e-08 [1.0001501] [1.0994585]\n",
      "2000 4.695122e-08 [1.0001403] [1.0994937]\n",
      "[6.100195]\n",
      "[3.5998445]\n",
      "[2.5997043 4.599985 ]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([1], name = 'weight'))\n",
    "b = tf.Variable(tf.random_normal([1], name = 'bias'))\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "hypothesis = X*W + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],\n",
    "                                        feed_dict= {X:[1,2,3,4,5], Y:[2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step %20 == 0:\n",
    "        print( step, cost_val, W_val, b_val)\n",
    "\n",
    "\n",
    "print(sess.run(hypothesis, feed_dict={X:[5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X:[2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X:[1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0044961 2.0009649 2.9974334]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict={X:[5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab 03 - Linear Regression의 cost 최소화의 TensorFlow 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "#Our hypothesis for linear model X*W\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "for i in range(-30, 50):\n",
    "    feed_W = i *0.1\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict={W: feed_W})\n",
    "    W_val.append(curr_W)\n",
    "    cost_val.append(curr_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(W_val, cost_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.6534402 [1.343661]\n",
      "1 0.47031188 [1.1832858]\n",
      "2 0.13377751 [1.0977525]\n",
      "3 0.038052317 [1.0521346]\n",
      "4 0.010823723 [1.0278051]\n",
      "5 0.0030787543 [1.0148294]\n",
      "6 0.0008757451 [1.007909]\n",
      "7 0.00024911042 [1.0042182]\n",
      "8 7.085722e-05 [1.0022497]\n",
      "9 2.0155532e-05 [1.0011998]\n",
      "10 5.7328853e-06 [1.0006399]\n",
      "11 1.6305191e-06 [1.0003413]\n",
      "12 4.6377187e-07 [1.000182]\n",
      "13 1.3182478e-07 [1.000097]\n",
      "14 3.7473797e-08 [1.0000517]\n",
      "15 1.0596594e-08 [1.0000275]\n",
      "16 2.999471e-09 [1.0000147]\n",
      "17 8.6663476e-10 [1.0000079]\n",
      "18 2.407461e-10 [1.0000042]\n",
      "19 7.021583e-11 [1.0000023]\n",
      "20 1.9895197e-11 [1.0000012]\n"
     ]
    }
   ],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name= 'weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X*W\n",
    "\n",
    "cost = tf.reduce_sum(tf.square(hypothesis-Y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W*X-Y)*X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -3.0\n",
      "1 0.7333336\n",
      "2 0.98222226\n",
      "3 0.9988148\n",
      "4 0.99992096\n",
      "5 0.9999947\n",
      "6 0.99999964\n",
      "7 0.99999994\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 1.0\n",
      "24 1.0\n",
      "25 1.0\n",
      "26 1.0\n",
      "27 1.0\n",
      "28 1.0\n",
      "29 1.0\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 1.0\n",
      "33 1.0\n",
      "34 1.0\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 1.0\n",
      "39 1.0\n",
      "40 1.0\n",
      "41 1.0\n",
      "42 1.0\n",
      "43 1.0\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 1.0\n",
      "47 1.0\n",
      "48 1.0\n",
      "49 1.0\n",
      "50 1.0\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 1.0\n",
      "54 1.0\n",
      "55 1.0\n",
      "56 1.0\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 1.0\n",
      "67 1.0\n",
      "68 1.0\n",
      "69 1.0\n",
      "70 1.0\n",
      "71 1.0\n",
      "72 1.0\n",
      "73 1.0\n",
      "74 1.0\n",
      "75 1.0\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 1.0\n",
      "89 1.0\n",
      "90 1.0\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 1.0\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 1.0\n"
     ]
    }
   ],
   "source": [
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "W = tf.Variable(-3.0)\n",
    "\n",
    "hypothesis = X*W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [37.333332, 5.0, [(37.333336, 5.0)]]\n",
      "1 [33.84889, 4.6266665, [(33.84889, 4.6266665)]]\n",
      "2 [30.689657, 4.2881775, [(30.689657, 4.2881775)]]\n",
      "3 [27.825287, 3.9812808, [(27.825287, 3.9812808)]]\n",
      "4 [25.228262, 3.703028, [(25.228262, 3.703028)]]\n",
      "5 [22.873621, 3.4507453, [(22.873623, 3.4507453)]]\n",
      "6 [20.738752, 3.2220092, [(20.73875, 3.2220092)]]\n",
      "7 [18.803137, 3.0146217, [(18.803137, 3.0146217)]]\n",
      "8 [17.048176, 2.8265903, [(17.048176, 2.8265903)]]\n",
      "9 [15.457013, 2.6561086, [(15.457014, 2.6561086)]]\n",
      "10 [14.014359, 2.5015385, [(14.01436, 2.5015385)]]\n",
      "11 [12.706352, 2.361395, [(12.706352, 2.361395)]]\n",
      "12 [11.520427, 2.2343314, [(11.520427, 2.2343314)]]\n",
      "13 [10.445186, 2.119127, [(10.445185, 2.119127)]]\n",
      "14 [9.470302, 2.0146751, [(9.470302, 2.0146751)]]\n",
      "15 [8.586407, 1.9199722, [(8.586407, 1.9199722)]]\n",
      "16 [7.785009, 1.8341081, [(7.785009, 1.8341081)]]\n",
      "17 [7.0584083, 1.756258, [(7.0584083, 1.756258)]]\n",
      "18 [6.399624, 1.685674, [(6.399624, 1.685674)]]\n",
      "19 [5.8023257, 1.6216778, [(5.8023252, 1.6216778)]]\n",
      "20 [5.260776, 1.5636545, [(5.260776, 1.5636545)]]\n",
      "21 [4.7697697, 1.5110468, [(4.7697697, 1.5110468)]]\n",
      "22 [4.324591, 1.4633491, [(4.324591, 1.4633491)]]\n",
      "23 [3.9209633, 1.4201032, [(3.9209635, 1.4201032)]]\n",
      "24 [3.5550067, 1.3808936, [(3.5550067, 1.3808936)]]\n",
      "25 [3.2232056, 1.3453435, [(3.2232056, 1.3453435)]]\n",
      "26 [2.9223735, 1.3131114, [(2.9223735, 1.3131114)]]\n",
      "27 [2.6496189, 1.2838877, [(2.6496186, 1.2838877)]]\n",
      "28 [2.4023216, 1.2573916, [(2.4023216, 1.2573916)]]\n",
      "29 [2.178105, 1.2333684, [(2.178105, 1.2333684)]]\n",
      "30 [1.9748148, 1.2115873, [(1.9748147, 1.2115873)]]\n",
      "31 [1.7904993, 1.1918392, [(1.7904994, 1.1918392)]]\n",
      "32 [1.623386, 1.1739342, [(1.6233861, 1.1739342)]]\n",
      "33 [1.4718695, 1.1577003, [(1.4718695, 1.1577003)]]\n",
      "34 [1.3344955, 1.1429816, [(1.3344957, 1.1429816)]]\n",
      "35 [1.2099417, 1.1296366, [(1.2099419, 1.1296366)]]\n",
      "36 [1.0970144, 1.1175373, [(1.0970144, 1.1175373)]]\n",
      "37 [0.9946267, 1.1065671, [(0.9946267, 1.1065671)]]\n",
      "38 [0.90179497, 1.0966209, [(0.901795, 1.0966209)]]\n",
      "39 [0.8176275, 1.087603, [(0.81762755, 1.087603)]]\n",
      "40 [0.7413151, 1.0794266, [(0.7413151, 1.0794266)]]\n",
      "41 [0.67212623, 1.0720135, [(0.67212623, 1.0720135)]]\n",
      "42 [0.609394, 1.0652922, [(0.609394, 1.0652922)]]\n",
      "43 [0.5525169, 1.0591983, [(0.5525169, 1.0591983)]]\n",
      "44 [0.50094914, 1.0536731, [(0.50094914, 1.0536731)]]\n",
      "45 [0.45419374, 1.0486636, [(0.45419377, 1.0486636)]]\n",
      "46 [0.41180158, 1.0441216, [(0.41180158, 1.0441216)]]\n",
      "47 [0.37336722, 1.0400037, [(0.37336725, 1.0400037)]]\n",
      "48 [0.33851996, 1.03627, [(0.33852, 1.03627)]]\n",
      "49 [0.30692515, 1.0328848, [(0.30692515, 1.0328848)]]\n",
      "50 [0.27827826, 1.0298156, [(0.2782783, 1.0298156)]]\n",
      "51 [0.25230527, 1.0270327, [(0.25230527, 1.0270327)]]\n",
      "52 [0.2287569, 1.0245097, [(0.2287569, 1.0245097)]]\n",
      "53 [0.20740573, 1.022222, [(0.20740573, 1.022222)]]\n",
      "54 [0.18804836, 1.020148, [(0.18804836, 1.020148)]]\n",
      "55 [0.17049654, 1.0182675, [(0.17049655, 1.0182675)]]\n",
      "56 [0.15458433, 1.0165626, [(0.15458433, 1.0165626)]]\n",
      "57 [0.14015675, 1.0150168, [(0.14015675, 1.0150168)]]\n",
      "58 [0.12707591, 1.0136153, [(0.12707591, 1.0136153)]]\n",
      "59 [0.11521538, 1.0123445, [(0.11521538, 1.0123445)]]\n",
      "60 [0.10446167, 1.0111923, [(0.10446167, 1.0111923)]]\n",
      "61 [0.09471202, 1.0101477, [(0.09471202, 1.0101477)]]\n",
      "62 [0.08587202, 1.0092006, [(0.08587202, 1.0092006)]]\n",
      "63 [0.07785805, 1.0083419, [(0.07785805, 1.0083419)]]\n",
      "64 [0.07059129, 1.0075634, [(0.07059129, 1.0075634)]]\n",
      "65 [0.06400236, 1.0068574, [(0.06400236, 1.0068574)]]\n",
      "66 [0.05802846, 1.0062174, [(0.05802846, 1.0062174)]]\n",
      "67 [0.052612226, 1.005637, [(0.052612226, 1.005637)]]\n",
      "68 [0.047702473, 1.005111, [(0.047702473, 1.005111)]]\n",
      "69 [0.043249767, 1.0046339, [(0.043249767, 1.0046339)]]\n",
      "70 [0.03921318, 1.0042014, [(0.03921318, 1.0042014)]]\n",
      "71 [0.035553534, 1.0038093, [(0.035553537, 1.0038093)]]\n",
      "72 [0.032236177, 1.0034539, [(0.03223618, 1.0034539)]]\n",
      "73 [0.029227654, 1.0031315, [(0.029227655, 1.0031315)]]\n",
      "74 [0.02649951, 1.0028392, [(0.02649951, 1.0028392)]]\n",
      "75 [0.024025917, 1.0025742, [(0.024025917, 1.0025742)]]\n",
      "76 [0.021783749, 1.002334, [(0.02178375, 1.002334)]]\n",
      "77 [0.01975123, 1.0021162, [(0.019751232, 1.0021162)]]\n",
      "78 [0.017907381, 1.0019187, [(0.017907381, 1.0019187)]]\n",
      "79 [0.016236702, 1.0017396, [(0.016236704, 1.0017396)]]\n",
      "80 [0.014720838, 1.0015773, [(0.014720838, 1.0015773)]]\n",
      "81 [0.01334699, 1.00143, [(0.013346991, 1.00143)]]\n",
      "82 [0.012100856, 1.0012965, [(0.012100856, 1.0012965)]]\n",
      "83 [0.010971785, 1.0011755, [(0.010971785, 1.0011755)]]\n",
      "84 [0.0099481745, 1.0010659, [(0.0099481745, 1.0010659)]]\n",
      "85 [0.009018898, 1.0009663, [(0.009018898, 1.0009663)]]\n",
      "86 [0.008176883, 1.0008761, [(0.008176884, 1.0008761)]]\n",
      "87 [0.007413149, 1.0007943, [(0.007413149, 1.0007943)]]\n",
      "88 [0.006721576, 1.0007201, [(0.006721576, 1.0007201)]]\n",
      "89 [0.0060940585, 1.0006529, [(0.0060940585, 1.0006529)]]\n",
      "90 [0.005525271, 1.000592, [(0.0055252714, 1.000592)]]\n",
      "91 [0.0050098896, 1.0005368, [(0.0050098896, 1.0005368)]]\n",
      "92 [0.004542589, 1.0004867, [(0.004542589, 1.0004867)]]\n",
      "93 [0.0041189194, 1.0004413, [(0.0041189194, 1.0004413)]]\n",
      "94 [0.0037339528, 1.0004001, [(0.003733953, 1.0004001)]]\n",
      "95 [0.0033854644, 1.0003628, [(0.0033854644, 1.0003628)]]\n",
      "96 [0.0030694802, 1.0003289, [(0.0030694804, 1.0003289)]]\n",
      "97 [0.0027837753, 1.0002983, [(0.0027837753, 1.0002983)]]\n",
      "98 [0.0025234222, 1.0002704, [(0.0025234222, 1.0002704)]]\n",
      "99 [0.0022875469, 1.0002451, [(0.0022875469, 1.0002451)]]\n"
     ]
    }
   ],
   "source": [
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "# Set wrong model weights\n",
    "W = tf.Variable(5.)\n",
    "# Linear model\n",
    "hypothesis = X * W\n",
    "# Manual gradient\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) * 2\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "# Get gradients\n",
    "gvs = optimizer.compute_gradients(cost, [W])\n",
    "# Apply gradients\n",
    "apply_gradients = optimizer.apply_gradients(gvs)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "   print(step, sess.run([gradient, W, gvs]))\n",
    "   sess.run(apply_gradients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab 04 multi-variable linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  31725.275 \n",
      "Prediction:\n",
      " [-12.616561    -1.4282908   -8.788703    -5.93383     -0.66677046]\n",
      "10 Cost:  13.588652 \n",
      "Prediction:\n",
      " [144.92728 187.90367 177.77586 197.228   143.74178]\n",
      "20 Cost:  13.24246 \n",
      "Prediction:\n",
      " [145.41664 188.46794 178.34435 197.84476 144.16812]\n",
      "30 Cost:  13.186864 \n",
      "Prediction:\n",
      " [145.43077 188.46104 178.35002 197.84868 144.15886]\n",
      "40 Cost:  13.131579 \n",
      "Prediction:\n",
      " [145.44342 188.45247 178.35402 197.85072 144.1483 ]\n",
      "50 Cost:  13.076581 \n",
      "Prediction:\n",
      " [145.45604 188.44391 178.358   197.85277 144.13777]\n",
      "60 Cost:  13.021894 \n",
      "Prediction:\n",
      " [145.46863 188.43538 178.36195 197.85481 144.12727]\n",
      "70 Cost:  12.967445 \n",
      "Prediction:\n",
      " [145.48119 188.42686 178.36594 197.85686 144.11679]\n",
      "80 Cost:  12.913351 \n",
      "Prediction:\n",
      " [145.49368 188.41837 178.36986 197.85886 144.10634]\n",
      "90 Cost:  12.8595 \n",
      "Prediction:\n",
      " [145.50616 188.40988 178.3738  197.86087 144.09593]\n",
      "100 Cost:  12.805986 \n",
      "Prediction:\n",
      " [145.5186  188.40144 178.37772 197.86287 144.08554]\n",
      "110 Cost:  12.752649 \n",
      "Prediction:\n",
      " [145.53102 188.39299 178.3816  197.86485 144.07516]\n",
      "120 Cost:  12.699671 \n",
      "Prediction:\n",
      " [145.54341 188.3846  178.38553 197.86687 144.06485]\n",
      "130 Cost:  12.646945 \n",
      "Prediction:\n",
      " [145.55576 188.3762  178.3894  197.86884 144.05453]\n",
      "140 Cost:  12.594498 \n",
      "Prediction:\n",
      " [145.56808 188.36786 178.39328 197.8708  144.04427]\n",
      "150 Cost:  12.542425 \n",
      "Prediction:\n",
      " [145.58035 188.35953 178.39716 197.8728  144.03404]\n",
      "160 Cost:  12.490461 \n",
      "Prediction:\n",
      " [145.5926  188.35118 178.40102 197.87473 144.02382]\n",
      "170 Cost:  12.43883 \n",
      "Prediction:\n",
      " [145.60483 188.34288 178.40486 197.8767  144.01361]\n",
      "180 Cost:  12.38751 \n",
      "Prediction:\n",
      " [145.61702 188.33463 178.40869 197.87863 144.00346]\n",
      "190 Cost:  12.33643 \n",
      "Prediction:\n",
      " [145.62918 188.32637 178.41254 197.88058 143.99335]\n",
      "200 Cost:  12.285629 \n",
      "Prediction:\n",
      " [145.6413  188.31813 178.41635 197.8825  143.98325]\n",
      "210 Cost:  12.235089 \n",
      "Prediction:\n",
      " [145.6534  188.30994 178.4202  197.88446 143.97318]\n",
      "220 Cost:  12.184821 \n",
      "Prediction:\n",
      " [145.66547 188.30176 178.424   197.88638 143.96315]\n",
      "230 Cost:  12.134799 \n",
      "Prediction:\n",
      " [145.67749 188.29358 178.42776 197.88828 143.95312]\n",
      "240 Cost:  12.085062 \n",
      "Prediction:\n",
      " [145.68948 188.28543 178.43155 197.89018 143.94315]\n",
      "250 Cost:  12.035619 \n",
      "Prediction:\n",
      " [145.70145 188.27733 178.43533 197.8921  143.93318]\n",
      "260 Cost:  11.9863405 \n",
      "Prediction:\n",
      " [145.7134  188.26923 178.4391  197.89398 143.92325]\n",
      "270 Cost:  11.937372 \n",
      "Prediction:\n",
      " [145.7253  188.26114 178.44286 197.89587 143.91335]\n",
      "280 Cost:  11.888693 \n",
      "Prediction:\n",
      " [145.73717 188.2531  178.44661 197.89777 143.90347]\n",
      "290 Cost:  11.840229 \n",
      "Prediction:\n",
      " [145.74902 188.24507 178.45033 197.89963 143.89365]\n",
      "300 Cost:  11.792026 \n",
      "Prediction:\n",
      " [145.76082 188.23703 178.45406 197.90149 143.88382]\n",
      "310 Cost:  11.744061 \n",
      "Prediction:\n",
      " [145.77261 188.22905 178.45776 197.90335 143.87402]\n",
      "320 Cost:  11.696381 \n",
      "Prediction:\n",
      " [145.78436 188.22108 178.46149 197.90521 143.86427]\n",
      "330 Cost:  11.648989 \n",
      "Prediction:\n",
      " [145.79607 188.21313 178.46518 197.90707 143.85454]\n",
      "340 Cost:  11.601759 \n",
      "Prediction:\n",
      " [145.80777 188.20522 178.46886 197.90889 143.84483]\n",
      "350 Cost:  11.554825 \n",
      "Prediction:\n",
      " [145.81941 188.1973  178.47253 197.91072 143.83514]\n",
      "360 Cost:  11.508123 \n",
      "Prediction:\n",
      " [145.83104 188.1894  178.4762  197.91254 143.8255 ]\n",
      "370 Cost:  11.4617 \n",
      "Prediction:\n",
      " [145.84262 188.18153 178.47986 197.91437 143.81587]\n",
      "380 Cost:  11.415479 \n",
      "Prediction:\n",
      " [145.8542  188.1737  178.48352 197.9162  143.80627]\n",
      "390 Cost:  11.369515 \n",
      "Prediction:\n",
      " [145.86572 188.16586 178.48715 197.91798 143.7967 ]\n",
      "400 Cost:  11.32382 \n",
      "Prediction:\n",
      " [145.87723 188.15808 178.49078 197.91978 143.78717]\n",
      "410 Cost:  11.278273 \n",
      "Prediction:\n",
      " [145.88872 188.15028 178.49442 197.92159 143.77765]\n",
      "420 Cost:  11.233059 \n",
      "Prediction:\n",
      " [145.90016 188.14253 178.49803 197.9234  143.76816]\n",
      "430 Cost:  11.188074 \n",
      "Prediction:\n",
      " [145.91158 188.1348  178.50162 197.92517 143.75871]\n",
      "440 Cost:  11.143242 \n",
      "Prediction:\n",
      " [145.92297 188.12708 178.50523 197.92694 143.74927]\n",
      "450 Cost:  11.098756 \n",
      "Prediction:\n",
      " [145.93431 188.11937 178.5088  197.92871 143.73987]\n",
      "460 Cost:  11.054431 \n",
      "Prediction:\n",
      " [145.94563 188.11168 178.51237 197.93047 143.73047]\n",
      "470 Cost:  11.010385 \n",
      "Prediction:\n",
      " [145.95692 188.10403 178.51595 197.93222 143.72112]\n",
      "480 Cost:  10.96652 \n",
      "Prediction:\n",
      " [145.9682  188.09639 178.5195  197.93398 143.71179]\n",
      "490 Cost:  10.92291 \n",
      "Prediction:\n",
      " [145.97943 188.08878 178.52307 197.93571 143.70248]\n",
      "500 Cost:  10.879529 \n",
      "Prediction:\n",
      " [145.99065 188.08118 178.52661 197.93747 143.69322]\n",
      "510 Cost:  10.836405 \n",
      "Prediction:\n",
      " [146.00182 188.07361 178.53014 197.9392  143.68398]\n",
      "520 Cost:  10.793447 \n",
      "Prediction:\n",
      " [146.01299 188.06606 178.53366 197.94093 143.67476]\n",
      "530 Cost:  10.75075 \n",
      "Prediction:\n",
      " [146.0241  188.05852 178.53719 197.94264 143.66556]\n",
      "540 Cost:  10.70828 \n",
      "Prediction:\n",
      " [146.03519 188.05101 178.54068 197.94435 143.65639]\n",
      "550 Cost:  10.666008 \n",
      "Prediction:\n",
      " [146.04623 188.04349 178.54417 197.94604 143.64723]\n",
      "560 Cost:  10.623957 \n",
      "Prediction:\n",
      " [146.05728 188.03601 178.54767 197.94777 143.63812]\n",
      "570 Cost:  10.582152 \n",
      "Prediction:\n",
      " [146.06828 188.02856 178.55113 197.94945 143.62903]\n",
      "580 Cost:  10.540586 \n",
      "Prediction:\n",
      " [146.07924 188.02112 178.55458 197.95113 143.61995]\n",
      "590 Cost:  10.499194 \n",
      "Prediction:\n",
      " [146.09018 188.01369 178.55804 197.9528  143.6109 ]\n",
      "600 Cost:  10.458003 \n",
      "Prediction:\n",
      " [146.1011  188.00629 178.56151 197.95448 143.60188]\n",
      "610 Cost:  10.417102 \n",
      "Prediction:\n",
      " [146.11198 187.99892 178.56496 197.95616 143.59291]\n",
      "620 Cost:  10.376329 \n",
      "Prediction:\n",
      " [146.12285 187.99155 178.56839 197.95781 143.58394]\n",
      "630 Cost:  10.335836 \n",
      "Prediction:\n",
      " [146.13367 187.9842  178.57181 197.95946 143.575  ]\n",
      "640 Cost:  10.295486 \n",
      "Prediction:\n",
      " [146.14449 187.97688 178.57523 197.96112 143.56607]\n",
      "650 Cost:  10.255402 \n",
      "Prediction:\n",
      " [146.15526 187.96959 178.57863 197.96275 143.55719]\n",
      "660 Cost:  10.215548 \n",
      "Prediction:\n",
      " [146.16599 187.9623  178.58203 197.9644  143.54832]\n",
      "670 Cost:  10.175839 \n",
      "Prediction:\n",
      " [146.17671 187.95503 178.5854  197.96602 143.53947]\n",
      "680 Cost:  10.136369 \n",
      "Prediction:\n",
      " [146.1874  187.94778 178.58879 197.96764 143.53065]\n",
      "690 Cost:  10.097122 \n",
      "Prediction:\n",
      " [146.19806 187.94057 178.59218 197.96928 143.52188]\n",
      "700 Cost:  10.058061 \n",
      "Prediction:\n",
      " [146.2087  187.93336 178.59554 197.97089 143.51312]\n",
      "710 Cost:  10.019167 \n",
      "Prediction:\n",
      " [146.2193  187.92616 178.59888 197.97247 143.50436]\n",
      "720 Cost:  9.980531 \n",
      "Prediction:\n",
      " [146.22987 187.919   178.60223 197.97408 143.49565]\n",
      "730 Cost:  9.942091 \n",
      "Prediction:\n",
      " [146.24042 187.91185 178.60558 197.97568 143.48697]\n",
      "740 Cost:  9.903859 \n",
      "Prediction:\n",
      " [146.25095 187.90474 178.6089  197.97728 143.4783 ]\n",
      "750 Cost:  9.865786 \n",
      "Prediction:\n",
      " [146.26143 187.8976  178.6122  197.97884 143.46965]\n",
      "760 Cost:  9.827954 \n",
      "Prediction:\n",
      " [146.2719  187.89052 178.61552 197.98042 143.46104]\n",
      "770 Cost:  9.790279 \n",
      "Prediction:\n",
      " [146.28235 187.88344 178.61882 197.98201 143.45245]\n",
      "780 Cost:  9.752851 \n",
      "Prediction:\n",
      " [146.29274 187.87639 178.62212 197.98355 143.44388]\n",
      "790 Cost:  9.715556 \n",
      "Prediction:\n",
      " [146.30315 187.86935 178.62543 197.98514 143.43535]\n",
      "800 Cost:  9.678474 \n",
      "Prediction:\n",
      " [146.3135  187.86234 178.62872 197.9867  143.42683]\n",
      "810 Cost:  9.641628 \n",
      "Prediction:\n",
      " [146.32384 187.85535 178.63199 197.98825 143.41835]\n",
      "820 Cost:  9.604931 \n",
      "Prediction:\n",
      " [146.33414 187.84836 178.63524 197.98978 143.40987]\n",
      "830 Cost:  9.568425 \n",
      "Prediction:\n",
      " [146.34442 187.8414  178.63847 197.9913  143.40141]\n",
      "840 Cost:  9.53212 \n",
      "Prediction:\n",
      " [146.35468 187.83446 178.64174 197.99284 143.393  ]\n",
      "850 Cost:  9.495985 \n",
      "Prediction:\n",
      " [146.3649  187.82751 178.64497 197.99437 143.3846 ]\n",
      "860 Cost:  9.46011 \n",
      "Prediction:\n",
      " [146.37508 187.82062 178.6482  197.99588 143.37622]\n",
      "870 Cost:  9.424342 \n",
      "Prediction:\n",
      " [146.38525 187.81372 178.65143 197.9974  143.36786]\n",
      "880 Cost:  9.388822 \n",
      "Prediction:\n",
      " [146.39539 187.80685 178.65463 197.9989  143.35954]\n",
      "890 Cost:  9.353428 \n",
      "Prediction:\n",
      " [146.4055  187.79999 178.65784 198.0004  143.35123]\n",
      "900 Cost:  9.31827 \n",
      "Prediction:\n",
      " [146.41559 187.79317 178.66104 198.00189 143.34296]\n",
      "910 Cost:  9.283255 \n",
      "Prediction:\n",
      " [146.42566 187.78635 178.66422 198.00339 143.33469]\n",
      "920 Cost:  9.248457 \n",
      "Prediction:\n",
      " [146.4357  187.77956 178.66739 198.00488 143.32646]\n",
      "930 Cost:  9.213835 \n",
      "Prediction:\n",
      " [146.4457  187.77277 178.67056 198.00635 143.31825]\n",
      "940 Cost:  9.179381 \n",
      "Prediction:\n",
      " [146.45569 187.76602 178.67374 198.00783 143.31007]\n",
      "950 Cost:  9.145073 \n",
      "Prediction:\n",
      " [146.46565 187.75926 178.6769  198.0093  143.30191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960 Cost:  9.1109705 \n",
      "Prediction:\n",
      " [146.47559 187.75253 178.68004 198.01076 143.29376]\n",
      "970 Cost:  9.077057 \n",
      "Prediction:\n",
      " [146.4855  187.74585 178.6832  198.01222 143.28566]\n",
      "980 Cost:  9.043322 \n",
      "Prediction:\n",
      " [146.49539 187.73917 178.68633 198.01369 143.27757]\n",
      "990 Cost:  9.009756 \n",
      "Prediction:\n",
      " [146.50523 187.73247 178.68945 198.01514 143.2695 ]\n",
      "1000 Cost:  8.976351 \n",
      "Prediction:\n",
      " [146.51506 187.72581 178.69257 198.01656 143.26144]\n",
      "1010 Cost:  8.943127 \n",
      "Prediction:\n",
      " [146.52487 187.7192  178.69568 198.01799 143.25342]\n",
      "1020 Cost:  8.910062 \n",
      "Prediction:\n",
      " [146.53465 187.71255 178.69878 198.01942 143.24542]\n",
      "1030 Cost:  8.8772 \n",
      "Prediction:\n",
      " [146.54439 187.70595 178.70186 198.02083 143.23743]\n",
      "1040 Cost:  8.844511 \n",
      "Prediction:\n",
      " [146.55412 187.69937 178.70494 198.02226 143.22949]\n",
      "1050 Cost:  8.8119545 \n",
      "Prediction:\n",
      " [146.56383 187.6928  178.70802 198.02368 143.22154]\n",
      "1060 Cost:  8.779563 \n",
      "Prediction:\n",
      " [146.5735  187.68623 178.71109 198.02507 143.21362]\n",
      "1070 Cost:  8.747401 \n",
      "Prediction:\n",
      " [146.58315 187.6797  178.71416 198.02649 143.20575]\n",
      "1080 Cost:  8.715339 \n",
      "Prediction:\n",
      " [146.59277 187.67317 178.71721 198.02788 143.19788]\n",
      "1090 Cost:  8.683502 \n",
      "Prediction:\n",
      " [146.60236 187.66667 178.72025 198.02925 143.19003]\n",
      "1100 Cost:  8.651785 \n",
      "Prediction:\n",
      " [146.61195 187.6602  178.72328 198.03065 143.18222]\n",
      "1110 Cost:  8.620241 \n",
      "Prediction:\n",
      " [146.62152 187.65375 178.72633 198.03206 143.17444]\n",
      "1120 Cost:  8.588877 \n",
      "Prediction:\n",
      " [146.63104 187.64731 178.72937 198.03343 143.16666]\n",
      "1130 Cost:  8.557641 \n",
      "Prediction:\n",
      " [146.64055 187.64087 178.73238 198.03479 143.1589 ]\n",
      "1140 Cost:  8.526607 \n",
      "Prediction:\n",
      " [146.65002 187.63446 178.73538 198.03616 143.15117]\n",
      "1150 Cost:  8.495733 \n",
      "Prediction:\n",
      " [146.65945 187.62805 178.73836 198.03749 143.14345]\n",
      "1160 Cost:  8.465005 \n",
      "Prediction:\n",
      " [146.66888 187.62167 178.74135 198.03885 143.13576]\n",
      "1170 Cost:  8.434435 \n",
      "Prediction:\n",
      " [146.67828 187.61531 178.74435 198.0402  143.12808]\n",
      "1180 Cost:  8.40402 \n",
      "Prediction:\n",
      " [146.68765 187.60895 178.74731 198.04153 143.12044]\n",
      "1190 Cost:  8.373777 \n",
      "Prediction:\n",
      " [146.697   187.60263 178.7503  198.04288 143.11282]\n",
      "1200 Cost:  8.343668 \n",
      "Prediction:\n",
      " [146.70634 187.59631 178.75327 198.04422 143.10522]\n",
      "1210 Cost:  8.313736 \n",
      "Prediction:\n",
      " [146.71564 187.59001 178.7562  198.04553 143.09763]\n",
      "1220 Cost:  8.28394 \n",
      "Prediction:\n",
      " [146.72493 187.58374 178.75916 198.04686 143.09009]\n",
      "1230 Cost:  8.254303 \n",
      "Prediction:\n",
      " [146.7342  187.5775  178.76212 198.0482  143.08257]\n",
      "1240 Cost:  8.224833 \n",
      "Prediction:\n",
      " [146.74342 187.57124 178.76505 198.0495  143.07504]\n",
      "1250 Cost:  8.195482 \n",
      "Prediction:\n",
      " [146.75264 187.565   178.76797 198.05081 143.06755]\n",
      "1260 Cost:  8.166321 \n",
      "Prediction:\n",
      " [146.76181 187.55879 178.77089 198.0521  143.06007]\n",
      "1270 Cost:  8.137329 \n",
      "Prediction:\n",
      " [146.77097 187.5526  178.77379 198.0534  143.05263]\n",
      "1280 Cost:  8.108414 \n",
      "Prediction:\n",
      " [146.78012 187.5464  178.77669 198.0547  143.04521]\n",
      "1290 Cost:  8.079703 \n",
      "Prediction:\n",
      " [146.78922 187.54024 178.77959 198.05597 143.0378 ]\n",
      "1300 Cost:  8.051111 \n",
      "Prediction:\n",
      " [146.79831 187.53409 178.78249 198.05725 143.03041]\n",
      "1310 Cost:  8.022738 \n",
      "Prediction:\n",
      " [146.80736 187.52797 178.78537 198.05855 143.02303]\n",
      "1320 Cost:  7.994438 \n",
      "Prediction:\n",
      " [146.8164  187.52185 178.78824 198.05981 143.01569]\n",
      "1330 Cost:  7.9662385 \n",
      "Prediction:\n",
      " [146.82544 187.51573 178.7911  198.06107 143.00836]\n",
      "1340 Cost:  7.938315 \n",
      "Prediction:\n",
      " [146.83441 187.50966 178.79396 198.06233 143.00107]\n",
      "1350 Cost:  7.9104357 \n",
      "Prediction:\n",
      " [146.84341 187.50362 178.79683 198.0636  142.9938 ]\n",
      "1360 Cost:  7.882772 \n",
      "Prediction:\n",
      " [146.85234 187.49756 178.79967 198.06485 142.98654]\n",
      "1370 Cost:  7.855193 \n",
      "Prediction:\n",
      " [146.86127 187.4915  178.80249 198.0661  142.9793 ]\n",
      "1380 Cost:  7.8277407 \n",
      "Prediction:\n",
      " [146.87018 187.48547 178.80533 198.06734 142.97208]\n",
      "1390 Cost:  7.8004827 \n",
      "Prediction:\n",
      " [146.87904 187.47948 178.80815 198.06856 142.96487]\n",
      "1400 Cost:  7.773371 \n",
      "Prediction:\n",
      " [146.88788 187.47348 178.81096 198.06978 142.95769]\n",
      "1410 Cost:  7.7463465 \n",
      "Prediction:\n",
      " [146.89673 187.46751 178.81378 198.07101 142.95053]\n",
      "1420 Cost:  7.7194834 \n",
      "Prediction:\n",
      " [146.90553 187.46155 178.81659 198.07224 142.94339]\n",
      "1430 Cost:  7.6927767 \n",
      "Prediction:\n",
      " [146.91432 187.45561 178.81937 198.07346 142.93628]\n",
      "1440 Cost:  7.6662154 \n",
      "Prediction:\n",
      " [146.92308 187.44969 178.82216 198.07468 142.92918]\n",
      "1450 Cost:  7.639743 \n",
      "Prediction:\n",
      " [146.93184 187.4438  178.82497 198.07588 142.92212]\n",
      "1460 Cost:  7.613439 \n",
      "Prediction:\n",
      " [146.94055 187.4379  178.82773 198.07709 142.91505]\n",
      "1470 Cost:  7.587274 \n",
      "Prediction:\n",
      " [146.94925 187.43204 178.8305  198.07828 142.90804]\n",
      "1480 Cost:  7.561212 \n",
      "Prediction:\n",
      " [146.95792 187.42615 178.83324 198.07945 142.901  ]\n",
      "1490 Cost:  7.535351 \n",
      "Prediction:\n",
      " [146.96655 187.4203  178.836   198.08066 142.89401]\n",
      "1500 Cost:  7.5095634 \n",
      "Prediction:\n",
      " [146.97519 187.41447 178.83876 198.08185 142.88704]\n",
      "1510 Cost:  7.4839163 \n",
      "Prediction:\n",
      " [146.98378 187.40865 178.84149 198.083   142.88008]\n",
      "1520 Cost:  7.458413 \n",
      "Prediction:\n",
      " [146.99237 187.40285 178.84422 198.08418 142.87315]\n",
      "1530 Cost:  7.4330244 \n",
      "Prediction:\n",
      " [147.00093 187.39706 178.84695 198.08534 142.86623]\n",
      "1540 Cost:  7.407801 \n",
      "Prediction:\n",
      " [147.00946 187.39128 178.84966 198.08652 142.85933]\n",
      "1550 Cost:  7.3826385 \n",
      "Prediction:\n",
      " [147.018   187.38554 178.85239 198.08768 142.85246]\n",
      "1560 Cost:  7.3576803 \n",
      "Prediction:\n",
      " [147.02647 187.37979 178.85509 198.08882 142.8456 ]\n",
      "1570 Cost:  7.3328567 \n",
      "Prediction:\n",
      " [147.03494 187.37408 178.85779 198.08998 142.83878]\n",
      "1580 Cost:  7.308093 \n",
      "Prediction:\n",
      " [147.0434  187.36835 178.86047 198.09113 142.83195]\n",
      "1590 Cost:  7.283489 \n",
      "Prediction:\n",
      " [147.05182 187.36266 178.86316 198.09225 142.82515]\n",
      "1600 Cost:  7.2590165 \n",
      "Prediction:\n",
      " [147.06023 187.35698 178.86584 198.0934  142.81837]\n",
      "1610 Cost:  7.2346587 \n",
      "Prediction:\n",
      " [147.0686  187.3513  178.8685  198.09451 142.81161]\n",
      "1620 Cost:  7.210439 \n",
      "Prediction:\n",
      " [147.07697 187.34566 178.87117 198.09564 142.80489]\n",
      "1630 Cost:  7.1863375 \n",
      "Prediction:\n",
      " [147.08531 187.34004 178.87386 198.09677 142.79817]\n",
      "1640 Cost:  7.1623545 \n",
      "Prediction:\n",
      " [147.09363 187.3344  178.8765  198.0979  142.79147]\n",
      "1650 Cost:  7.138485 \n",
      "Prediction:\n",
      " [147.10193 187.3288  178.87914 198.099   142.78479]\n",
      "1660 Cost:  7.1147537 \n",
      "Prediction:\n",
      " [147.1102  187.3232  178.88177 198.10011 142.77812]\n",
      "1670 Cost:  7.091153 \n",
      "Prediction:\n",
      " [147.11845 187.31764 178.88441 198.10121 142.77148]\n",
      "1680 Cost:  7.067659 \n",
      "Prediction:\n",
      " [147.12668 187.31207 178.88702 198.1023  142.76485]\n",
      "1690 Cost:  7.044286 \n",
      "Prediction:\n",
      " [147.1349  187.30653 178.88965 198.10341 142.75826]\n",
      "1700 Cost:  7.021042 \n",
      "Prediction:\n",
      " [147.14308 187.301   178.89226 198.10449 142.75166]\n",
      "1710 Cost:  6.9979033 \n",
      "Prediction:\n",
      " [147.15125 187.29546 178.89485 198.10558 142.7451 ]\n",
      "1720 Cost:  6.9748597 \n",
      "Prediction:\n",
      " [147.15942 187.28998 178.89748 198.10667 142.73857]\n",
      "1730 Cost:  6.9519835 \n",
      "Prediction:\n",
      " [147.16753 187.28448 178.90007 198.10773 142.73204]\n",
      "1740 Cost:  6.929193 \n",
      "Prediction:\n",
      " [147.17564 187.27902 178.90266 198.10881 142.72552]\n",
      "1750 Cost:  6.9065156 \n",
      "Prediction:\n",
      " [147.18372 187.27353 178.90523 198.10986 142.71902]\n",
      "1760 Cost:  6.883981 \n",
      "Prediction:\n",
      " [147.19177 187.2681  178.9078  198.11092 142.71255]\n",
      "1770 Cost:  6.861557 \n",
      "Prediction:\n",
      " [147.19981 187.26266 178.91037 198.11198 142.7061 ]\n",
      "1780 Cost:  6.8392067 \n",
      "Prediction:\n",
      " [147.20784 187.25723 178.91292 198.11302 142.69966]\n",
      "1790 Cost:  6.8170266 \n",
      "Prediction:\n",
      " [147.21584 187.25185 178.91548 198.11407 142.69325]\n",
      "1800 Cost:  6.7949615 \n",
      "Prediction:\n",
      " [147.2238  187.24644 178.91801 198.11513 142.68684]\n",
      "1810 Cost:  6.772935 \n",
      "Prediction:\n",
      " [147.2318  187.24109 178.92058 198.11618 142.68048]\n",
      "1820 Cost:  6.7510595 \n",
      "Prediction:\n",
      " [147.23973 187.23572 178.9231  198.1172  142.67412]\n",
      "1830 Cost:  6.7293067 \n",
      "Prediction:\n",
      " [147.24765 187.23038 178.92564 198.11824 142.66779]\n",
      "1840 Cost:  6.707666 \n",
      "Prediction:\n",
      " [147.25554 187.22504 178.92816 198.11926 142.66145]\n",
      "1850 Cost:  6.6861277 \n",
      "Prediction:\n",
      " [147.26341 187.21971 178.93068 198.12029 142.65514]\n",
      "1860 Cost:  6.6647186 \n",
      "Prediction:\n",
      " [147.27127 187.21442 178.93318 198.1213  142.64886]\n",
      "1870 Cost:  6.643407 \n",
      "Prediction:\n",
      " [147.27908 187.2091  178.93568 198.1223  142.64258]\n",
      "1880 Cost:  6.622199 \n",
      "Prediction:\n",
      " [147.28691 187.20384 178.93819 198.12332 142.63634]\n",
      "1890 Cost:  6.601091 \n",
      "Prediction:\n",
      " [147.29472 187.1986  178.94069 198.12434 142.63011]\n",
      "1900 Cost:  6.5801034 \n",
      "Prediction:\n",
      " [147.30249 187.19334 178.94318 198.12534 142.62389]\n",
      "1910 Cost:  6.5592146 \n",
      "Prediction:\n",
      " [147.31024 187.1881  178.94563 198.12633 142.61768]\n",
      "1920 Cost:  6.538433 \n",
      "Prediction:\n",
      " [147.31798 187.18288 178.94812 198.12732 142.61151]\n",
      "1930 Cost:  6.5177393 \n",
      "Prediction:\n",
      " [147.3257  187.17766 178.95059 198.12831 142.60535]\n",
      "1940 Cost:  6.497214 \n",
      "Prediction:\n",
      " [147.33337 187.17247 178.95303 198.12929 142.5992 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950 Cost:  6.476719 \n",
      "Prediction:\n",
      " [147.34106 187.1673  178.9555  198.13026 142.59308]\n",
      "1960 Cost:  6.4563804 \n",
      "Prediction:\n",
      " [147.34871 187.16212 178.95793 198.13124 142.58696]\n",
      "1970 Cost:  6.4360743 \n",
      "Prediction:\n",
      " [147.35637 187.15697 178.96039 198.13222 142.58087]\n",
      "1980 Cost:  6.415961 \n",
      "Prediction:\n",
      " [147.36395 187.15182 178.96281 198.13316 142.57478]\n",
      "1990 Cost:  6.395886 \n",
      "Prediction:\n",
      " [147.37158 187.14671 178.96526 198.13416 142.56876]\n",
      "2000 Cost:  6.3759565 \n",
      "Prediction:\n",
      " [147.37914 187.14159 178.96767 198.1351  142.5627 ]\n"
     ]
    }
   ],
   "source": [
    "x1_data=[73., 93., 89., 96., 73.]\n",
    "x2_data=[80., 88., 91., 98., 66.]\n",
    "x3_data=[75., 93., 90., 100., 70.]\n",
    "y_data=[152., 185., 180., 196., 142.]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name = 'weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name = 'weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name = 'weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = x1*w1 + x2*w2 + x3*w3 +b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                  feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    if step %10 ==0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  14362.208 \n",
      "Prediction:\n",
      " [[41.883358]\n",
      " [59.343464]\n",
      " [54.06951 ]\n",
      " [56.526466]\n",
      " [49.347702]]\n",
      "10 Cost:  9.632287 \n",
      "Prediction:\n",
      " [[147.87381]\n",
      " [186.71507]\n",
      " [179.58183]\n",
      " [193.20546]\n",
      " [146.49557]]\n",
      "20 Cost:  9.454999 \n",
      "Prediction:\n",
      " [[148.20554]\n",
      " [187.09285]\n",
      " [179.9649 ]\n",
      " [193.62186]\n",
      " [146.77914]]\n",
      "30 Cost:  9.409311 \n",
      "Prediction:\n",
      " [[148.21756]\n",
      " [187.08641]\n",
      " [179.96938]\n",
      " [193.62599]\n",
      " [146.76967]]\n",
      "40 Cost:  9.363907 \n",
      "Prediction:\n",
      " [[148.22855]\n",
      " [187.0788 ]\n",
      " [179.9727 ]\n",
      " [193.62881]\n",
      " [146.75931]]\n",
      "50 Cost:  9.318708 \n",
      "Prediction:\n",
      " [[148.23953]\n",
      " [187.07121]\n",
      " [179.976  ]\n",
      " [193.63167]\n",
      " [146.749  ]]\n",
      "60 Cost:  9.273778 \n",
      "Prediction:\n",
      " [[148.2505 ]\n",
      " [187.06369]\n",
      " [179.9793 ]\n",
      " [193.6345 ]\n",
      " [146.73871]]\n",
      "70 Cost:  9.229073 \n",
      "Prediction:\n",
      " [[148.26141]\n",
      " [187.05617]\n",
      " [179.98259]\n",
      " [193.63736]\n",
      " [146.72844]]\n",
      "80 Cost:  9.184634 \n",
      "Prediction:\n",
      " [[148.2723 ]\n",
      " [187.04865]\n",
      " [179.98586]\n",
      " [193.64017]\n",
      " [146.7182 ]]\n",
      "90 Cost:  9.140413 \n",
      "Prediction:\n",
      " [[148.28314]\n",
      " [187.04117]\n",
      " [179.98914]\n",
      " [193.64299]\n",
      " [146.70798]]\n",
      "100 Cost:  9.096474 \n",
      "Prediction:\n",
      " [[148.29398]\n",
      " [187.0337 ]\n",
      " [179.9924 ]\n",
      " [193.6458 ]\n",
      " [146.69781]]\n",
      "110 Cost:  9.052727 \n",
      "Prediction:\n",
      " [[148.30478]\n",
      " [187.02625]\n",
      " [179.99562]\n",
      " [193.6486 ]\n",
      " [146.68767]]\n",
      "120 Cost:  9.009171 \n",
      "Prediction:\n",
      " [[148.31552]\n",
      " [187.0188 ]\n",
      " [179.99889]\n",
      " [193.65141]\n",
      " [146.6775 ]]\n",
      "130 Cost:  8.965892 \n",
      "Prediction:\n",
      " [[148.32625]\n",
      " [187.01138]\n",
      " [180.00209]\n",
      " [193.65419]\n",
      " [146.66739]]\n",
      "140 Cost:  8.922872 \n",
      "Prediction:\n",
      " [[148.33699]\n",
      " [187.00403]\n",
      " [180.00534]\n",
      " [193.657  ]\n",
      " [146.65735]]\n",
      "150 Cost:  8.880053 \n",
      "Prediction:\n",
      " [[148.34766]\n",
      " [186.99664]\n",
      " [180.00851]\n",
      " [193.65974]\n",
      " [146.64728]]\n",
      "160 Cost:  8.837455 \n",
      "Prediction:\n",
      " [[148.35832]\n",
      " [186.9893 ]\n",
      " [180.01175]\n",
      " [193.66254]\n",
      " [146.63727]]\n",
      "170 Cost:  8.795108 \n",
      "Prediction:\n",
      " [[148.36894]\n",
      " [186.98198]\n",
      " [180.01494]\n",
      " [193.6653 ]\n",
      " [146.62727]]\n",
      "180 Cost:  8.7529745 \n",
      "Prediction:\n",
      " [[148.37955]\n",
      " [186.9747 ]\n",
      " [180.01814]\n",
      " [193.66808]\n",
      " [146.61731]]\n",
      "190 Cost:  8.711046 \n",
      "Prediction:\n",
      " [[148.39009]\n",
      " [186.96739]\n",
      " [180.0213 ]\n",
      " [193.67082]\n",
      " [146.60735]]\n",
      "200 Cost:  8.669375 \n",
      "Prediction:\n",
      " [[148.40062]\n",
      " [186.96011]\n",
      " [180.02446]\n",
      " [193.67355]\n",
      " [146.59743]]\n",
      "210 Cost:  8.627921 \n",
      "Prediction:\n",
      " [[148.41115]\n",
      " [186.95288]\n",
      " [180.02763]\n",
      " [193.6763 ]\n",
      " [146.58755]]\n",
      "220 Cost:  8.586662 \n",
      "Prediction:\n",
      " [[148.4216 ]\n",
      " [186.94563]\n",
      " [180.03078]\n",
      " [193.67903]\n",
      " [146.57767]]\n",
      "230 Cost:  8.54563 \n",
      "Prediction:\n",
      " [[148.43205]\n",
      " [186.93845]\n",
      " [180.03392]\n",
      " [193.68178]\n",
      " [146.56783]]\n",
      "240 Cost:  8.504857 \n",
      "Prediction:\n",
      " [[148.44244]\n",
      " [186.93123]\n",
      " [180.03703]\n",
      " [193.68446]\n",
      " [146.558  ]]\n",
      "250 Cost:  8.464326 \n",
      "Prediction:\n",
      " [[148.45285]\n",
      " [186.92409]\n",
      " [180.04019]\n",
      " [193.6872 ]\n",
      " [146.54825]]\n",
      "260 Cost:  8.423926 \n",
      "Prediction:\n",
      " [[148.46321]\n",
      " [186.91695]\n",
      " [180.0433 ]\n",
      " [193.68991]\n",
      " [146.53847]]\n",
      "270 Cost:  8.383798 \n",
      "Prediction:\n",
      " [[148.47353]\n",
      " [186.9098 ]\n",
      " [180.04639]\n",
      " [193.69258]\n",
      " [146.52872]]\n",
      "280 Cost:  8.343871 \n",
      "Prediction:\n",
      " [[148.48386]\n",
      " [186.90271]\n",
      " [180.04951]\n",
      " [193.69531]\n",
      " [146.51904]]\n",
      "290 Cost:  8.304187 \n",
      "Prediction:\n",
      " [[148.49411]\n",
      " [186.89561]\n",
      " [180.05258]\n",
      " [193.69798]\n",
      " [146.50935]]\n",
      "300 Cost:  8.264657 \n",
      "Prediction:\n",
      " [[148.50435]\n",
      " [186.88853]\n",
      " [180.05568]\n",
      " [193.70067]\n",
      " [146.49968]]\n",
      "310 Cost:  8.225397 \n",
      "Prediction:\n",
      " [[148.51457]\n",
      " [186.8815 ]\n",
      " [180.05875]\n",
      " [193.70332]\n",
      " [146.49005]]\n",
      "320 Cost:  8.186264 \n",
      "Prediction:\n",
      " [[148.52478]\n",
      " [186.87447]\n",
      " [180.06181]\n",
      " [193.70601]\n",
      " [146.48044]]\n",
      "330 Cost:  8.1474 \n",
      "Prediction:\n",
      " [[148.53493]\n",
      " [186.86745]\n",
      " [180.06485]\n",
      " [193.70865]\n",
      " [146.47084]]\n",
      "340 Cost:  8.10874 \n",
      "Prediction:\n",
      " [[148.54506]\n",
      " [186.86044]\n",
      " [180.0679 ]\n",
      " [193.7113 ]\n",
      " [146.46129]]\n",
      "350 Cost:  8.07028 \n",
      "Prediction:\n",
      " [[148.55518]\n",
      " [186.85349]\n",
      " [180.07094]\n",
      " [193.71397]\n",
      " [146.45177]]\n",
      "360 Cost:  8.032019 \n",
      "Prediction:\n",
      " [[148.56526]\n",
      " [186.84653]\n",
      " [180.07397]\n",
      " [193.71661]\n",
      " [146.44226]]\n",
      "370 Cost:  7.9939575 \n",
      "Prediction:\n",
      " [[148.57529]\n",
      " [186.83957]\n",
      " [180.07698]\n",
      " [193.71924]\n",
      " [146.43275]]\n",
      "380 Cost:  7.956128 \n",
      "Prediction:\n",
      " [[148.58533]\n",
      " [186.83269]\n",
      " [180.08003]\n",
      " [193.72191]\n",
      " [146.42332]]\n",
      "390 Cost:  7.918481 \n",
      "Prediction:\n",
      " [[148.59532]\n",
      " [186.82578]\n",
      " [180.08302]\n",
      " [193.7245 ]\n",
      " [146.41388]]\n",
      "400 Cost:  7.881044 \n",
      "Prediction:\n",
      " [[148.60527]\n",
      " [186.8189 ]\n",
      " [180.086  ]\n",
      " [193.72713]\n",
      " [146.40446]]\n",
      "410 Cost:  7.8438225 \n",
      "Prediction:\n",
      " [[148.61522]\n",
      " [186.81206]\n",
      " [180.089  ]\n",
      " [193.72975]\n",
      " [146.3951 ]]\n",
      "420 Cost:  7.8067408 \n",
      "Prediction:\n",
      " [[148.62515]\n",
      " [186.80518]\n",
      " [180.09196]\n",
      " [193.73235]\n",
      " [146.38574]]\n",
      "430 Cost:  7.769923 \n",
      "Prediction:\n",
      " [[148.63503]\n",
      " [186.79837]\n",
      " [180.09494]\n",
      " [193.73494]\n",
      " [146.3764 ]]\n",
      "440 Cost:  7.733278 \n",
      "Prediction:\n",
      " [[148.64488]\n",
      " [186.79156]\n",
      " [180.09792]\n",
      " [193.73753]\n",
      " [146.3671 ]]\n",
      "450 Cost:  7.6968193 \n",
      "Prediction:\n",
      " [[148.65471]\n",
      " [186.78479]\n",
      " [180.10088]\n",
      " [193.74013]\n",
      " [146.3578 ]]\n",
      "460 Cost:  7.6605897 \n",
      "Prediction:\n",
      " [[148.6645 ]\n",
      " [186.77803]\n",
      " [180.10379]\n",
      " [193.74269]\n",
      " [146.34854]]\n",
      "470 Cost:  7.6245413 \n",
      "Prediction:\n",
      " [[148.67429]\n",
      " [186.77129]\n",
      " [180.10677]\n",
      " [193.74529]\n",
      " [146.33932]]\n",
      "480 Cost:  7.5886245 \n",
      "Prediction:\n",
      " [[148.68405]\n",
      " [186.76453]\n",
      " [180.10966]\n",
      " [193.74785]\n",
      " [146.33011]]\n",
      "490 Cost:  7.5529337 \n",
      "Prediction:\n",
      " [[148.69377]\n",
      " [186.75783]\n",
      " [180.11258]\n",
      " [193.75041]\n",
      " [146.3209 ]]\n",
      "500 Cost:  7.5174623 \n",
      "Prediction:\n",
      " [[148.70348]\n",
      " [186.75114]\n",
      " [180.11551]\n",
      " [193.75299]\n",
      " [146.31177]]\n",
      "510 Cost:  7.482146 \n",
      "Prediction:\n",
      " [[148.71313]\n",
      " [186.74446]\n",
      " [180.11842]\n",
      " [193.75554]\n",
      " [146.30261]]\n",
      "520 Cost:  7.4470763 \n",
      "Prediction:\n",
      " [[148.72276]\n",
      " [186.73781]\n",
      " [180.1213 ]\n",
      " [193.75807]\n",
      " [146.2935 ]]\n",
      "530 Cost:  7.4121704 \n",
      "Prediction:\n",
      " [[148.73238]\n",
      " [186.73117]\n",
      " [180.12419]\n",
      " [193.76062]\n",
      " [146.28442]]\n",
      "540 Cost:  7.37742 \n",
      "Prediction:\n",
      " [[148.74199]\n",
      " [186.72455]\n",
      " [180.12706]\n",
      " [193.76314]\n",
      " [146.27536]]\n",
      "550 Cost:  7.3428407 \n",
      "Prediction:\n",
      " [[148.75154]\n",
      " [186.71794]\n",
      " [180.12994]\n",
      " [193.76567]\n",
      " [146.2663 ]]\n",
      "560 Cost:  7.308512 \n",
      "Prediction:\n",
      " [[148.76108]\n",
      " [186.71136]\n",
      " [180.13283]\n",
      " [193.76819]\n",
      " [146.2573 ]]\n",
      "570 Cost:  7.27431 \n",
      "Prediction:\n",
      " [[148.77058]\n",
      " [186.7048 ]\n",
      " [180.13568]\n",
      " [193.77072]\n",
      " [146.24829]]\n",
      "580 Cost:  7.2403336 \n",
      "Prediction:\n",
      " [[148.78008]\n",
      " [186.69826]\n",
      " [180.13852]\n",
      " [193.77322]\n",
      " [146.23933]]\n",
      "590 Cost:  7.206504 \n",
      "Prediction:\n",
      " [[148.78955]\n",
      " [186.69173]\n",
      " [180.14136]\n",
      " [193.77573]\n",
      " [146.2304 ]]\n",
      "600 Cost:  7.172886 \n",
      "Prediction:\n",
      " [[148.79895]\n",
      " [186.68521]\n",
      " [180.1442 ]\n",
      " [193.77821]\n",
      " [146.22145]]\n",
      "610 Cost:  7.139425 \n",
      "Prediction:\n",
      " [[148.80836]\n",
      " [186.67871]\n",
      " [180.147  ]\n",
      " [193.7807 ]\n",
      " [146.21255]]\n",
      "620 Cost:  7.1061277 \n",
      "Prediction:\n",
      " [[148.81776]\n",
      " [186.67226]\n",
      " [180.14983]\n",
      " [193.78322]\n",
      " [146.20369]]\n",
      "630 Cost:  7.0730667 \n",
      "Prediction:\n",
      " [[148.8271 ]\n",
      " [186.66579]\n",
      " [180.15263]\n",
      " [193.78568]\n",
      " [146.19484]]\n",
      "640 Cost:  7.040124 \n",
      "Prediction:\n",
      " [[148.83641]\n",
      " [186.65935]\n",
      " [180.15541]\n",
      " [193.78816]\n",
      " [146.18599]]\n",
      "650 Cost:  7.007388 \n",
      "Prediction:\n",
      " [[148.84573]\n",
      " [186.65294]\n",
      " [180.15823]\n",
      " [193.79063]\n",
      " [146.1772 ]]\n",
      "660 Cost:  6.9748106 \n",
      "Prediction:\n",
      " [[148.85501]\n",
      " [186.64651]\n",
      " [180.161  ]\n",
      " [193.79308]\n",
      " [146.16841]]\n",
      "670 Cost:  6.9424224 \n",
      "Prediction:\n",
      " [[148.86427]\n",
      " [186.64014]\n",
      " [180.1638 ]\n",
      " [193.79555]\n",
      " [146.15967]]\n",
      "680 Cost:  6.9101944 \n",
      "Prediction:\n",
      " [[148.87347]\n",
      " [186.63376]\n",
      " [180.16655]\n",
      " [193.79799]\n",
      " [146.15091]]\n",
      "690 Cost:  6.878175 \n",
      "Prediction:\n",
      " [[148.88268]\n",
      " [186.62741]\n",
      " [180.16931]\n",
      " [193.80043]\n",
      " [146.14221]]\n",
      "700 Cost:  6.846263 \n",
      "Prediction:\n",
      " [[148.89188]\n",
      " [186.62108]\n",
      " [180.17209]\n",
      " [193.80289]\n",
      " [146.13353]]\n",
      "710 Cost:  6.814508 \n",
      "Prediction:\n",
      " [[148.90102]\n",
      " [186.61476]\n",
      " [180.17482]\n",
      " [193.80533]\n",
      " [146.12483]]\n",
      "720 Cost:  6.7830124 \n",
      "Prediction:\n",
      " [[148.91013]\n",
      " [186.60846]\n",
      " [180.17755]\n",
      " [193.80774]\n",
      " [146.1162 ]]\n",
      "730 Cost:  6.7516356 \n",
      "Prediction:\n",
      " [[148.91924]\n",
      " [186.60217]\n",
      " [180.18027]\n",
      " [193.81015]\n",
      " [146.10757]]\n",
      "740 Cost:  6.720421 \n",
      "Prediction:\n",
      " [[148.9283 ]\n",
      " [186.5959 ]\n",
      " [180.183  ]\n",
      " [193.81258]\n",
      " [146.09897]]\n",
      "750 Cost:  6.689383 \n",
      "Prediction:\n",
      " [[148.93736]\n",
      " [186.58966]\n",
      " [180.18571]\n",
      " [193.815  ]\n",
      " [146.09041]]\n",
      "760 Cost:  6.6585264 \n",
      "Prediction:\n",
      " [[148.94637]\n",
      " [186.58344]\n",
      " [180.18845]\n",
      " [193.81741]\n",
      " [146.08185]]\n",
      "770 Cost:  6.6278 \n",
      "Prediction:\n",
      " [[148.95537]\n",
      " [186.57721]\n",
      " [180.19112]\n",
      " [193.8198 ]\n",
      " [146.0733 ]]\n",
      "780 Cost:  6.5972466 \n",
      "Prediction:\n",
      " [[148.96437]\n",
      " [186.57103]\n",
      " [180.19383]\n",
      " [193.82222]\n",
      " [146.06482]]\n",
      "790 Cost:  6.566855 \n",
      "Prediction:\n",
      " [[148.9733 ]\n",
      " [186.56485]\n",
      " [180.1965 ]\n",
      " [193.8246 ]\n",
      " [146.0563 ]]\n",
      "800 Cost:  6.53663 \n",
      "Prediction:\n",
      " [[148.98222]\n",
      " [186.55867]\n",
      " [180.19916]\n",
      " [193.82697]\n",
      " [146.04784]]\n",
      "810 Cost:  6.5066056 \n",
      "Prediction:\n",
      " [[148.99113]\n",
      " [186.55255]\n",
      " [180.20184]\n",
      " [193.82935]\n",
      " [146.03941]]\n",
      "820 Cost:  6.47671 \n",
      "Prediction:\n",
      " [[149.     ]\n",
      " [186.5464 ]\n",
      " [180.20451]\n",
      " [193.83171]\n",
      " [146.03099]]\n",
      "830 Cost:  6.4469733 \n",
      "Prediction:\n",
      " [[149.00885]\n",
      " [186.5403 ]\n",
      " [180.20715]\n",
      " [193.83409]\n",
      " [146.0226 ]]\n",
      "840 Cost:  6.417417 \n",
      "Prediction:\n",
      " [[149.01767]\n",
      " [186.5342 ]\n",
      " [180.2098 ]\n",
      " [193.83643]\n",
      " [146.01422]]\n",
      "850 Cost:  6.388001 \n",
      "Prediction:\n",
      " [[149.02647]\n",
      " [186.52812]\n",
      " [180.21245]\n",
      " [193.83879]\n",
      " [146.00587]]\n",
      "860 Cost:  6.3587046 \n",
      "Prediction:\n",
      " [[149.03526]\n",
      " [186.52205]\n",
      " [180.21509]\n",
      " [193.84116]\n",
      " [145.99754]]\n",
      "870 Cost:  6.329608 \n",
      "Prediction:\n",
      " [[149.044  ]\n",
      " [186.516  ]\n",
      " [180.21771]\n",
      " [193.84349]\n",
      " [145.98923]]\n",
      "880 Cost:  6.3006334 \n",
      "Prediction:\n",
      " [[149.05275]\n",
      " [186.50998]\n",
      " [180.22032]\n",
      " [193.84584]\n",
      " [145.98094]]\n",
      "890 Cost:  6.271867 \n",
      "Prediction:\n",
      " [[149.06143]\n",
      " [186.50397]\n",
      " [180.22293]\n",
      " [193.84816]\n",
      " [145.97267]]\n",
      "900 Cost:  6.2432013 \n",
      "Prediction:\n",
      " [[149.0701 ]\n",
      " [186.49797]\n",
      " [180.22551]\n",
      " [193.85048]\n",
      " [145.9644 ]]\n",
      "910 Cost:  6.2146926 \n",
      "Prediction:\n",
      " [[149.07878]\n",
      " [186.49197]\n",
      " [180.22812]\n",
      " [193.85283]\n",
      " [145.9562 ]]\n",
      "920 Cost:  6.1863785 \n",
      "Prediction:\n",
      " [[149.08742]\n",
      " [186.48602]\n",
      " [180.23071]\n",
      " [193.85513]\n",
      " [145.94801]]\n",
      "930 Cost:  6.158188 \n",
      "Prediction:\n",
      " [[149.09601]\n",
      " [186.48009]\n",
      " [180.23329]\n",
      " [193.85745]\n",
      " [145.93982]]\n",
      "940 Cost:  6.130124 \n",
      "Prediction:\n",
      " [[149.1046 ]\n",
      " [186.47414]\n",
      " [180.23587]\n",
      " [193.85976]\n",
      " [145.93166]]\n",
      "950 Cost:  6.1022215 \n",
      "Prediction:\n",
      " [[149.11316]\n",
      " [186.46822]\n",
      " [180.2384 ]\n",
      " [193.86205]\n",
      " [145.92351]]\n",
      "960 Cost:  6.0745263 \n",
      "Prediction:\n",
      " [[149.1217 ]\n",
      " [186.46234]\n",
      " [180.241  ]\n",
      " [193.86435]\n",
      " [145.91542]]\n",
      "970 Cost:  6.046933 \n",
      "Prediction:\n",
      " [[149.1302 ]\n",
      " [186.45645]\n",
      " [180.24355]\n",
      " [193.86664]\n",
      " [145.90732]]\n",
      "980 Cost:  6.019478 \n",
      "Prediction:\n",
      " [[149.1387 ]\n",
      " [186.45059]\n",
      " [180.24608]\n",
      " [193.86893]\n",
      " [145.89925]]\n",
      "990 Cost:  5.9922 \n",
      "Prediction:\n",
      " [[149.14717]\n",
      " [186.44475]\n",
      " [180.24861]\n",
      " [193.8712 ]\n",
      " [145.8912 ]]\n",
      "1000 Cost:  5.9650273 \n",
      "Prediction:\n",
      " [[149.15564]\n",
      " [186.43892]\n",
      " [180.25114]\n",
      " [193.87347]\n",
      " [145.88318]]\n",
      "1010 Cost:  5.938012 \n",
      "Prediction:\n",
      " [[149.16403]\n",
      " [186.43309]\n",
      " [180.25366]\n",
      " [193.87575]\n",
      " [145.87515]]\n",
      "1020 Cost:  5.9111466 \n",
      "Prediction:\n",
      " [[149.17244]\n",
      " [186.42728]\n",
      " [180.2562 ]\n",
      " [193.878  ]\n",
      " [145.86717]]\n",
      "1030 Cost:  5.884429 \n",
      "Prediction:\n",
      " [[149.18082]\n",
      " [186.42152]\n",
      " [180.2587 ]\n",
      " [193.88028]\n",
      " [145.8592 ]]\n",
      "1040 Cost:  5.8578477 \n",
      "Prediction:\n",
      " [[149.18916]\n",
      " [186.41574]\n",
      " [180.26118]\n",
      " [193.88252]\n",
      " [145.85126]]\n",
      "1050 Cost:  5.8314095 \n",
      "Prediction:\n",
      " [[149.1975 ]\n",
      " [186.40997]\n",
      " [180.26367]\n",
      " [193.88477]\n",
      " [145.84334]]\n",
      "1060 Cost:  5.8051057 \n",
      "Prediction:\n",
      " [[149.2058 ]\n",
      " [186.40424]\n",
      " [180.26617]\n",
      " [193.88702]\n",
      " [145.83543]]\n",
      "1070 Cost:  5.778926 \n",
      "Prediction:\n",
      " [[149.21407]\n",
      " [186.39851]\n",
      " [180.26866]\n",
      " [193.88927]\n",
      " [145.82753]]\n",
      "1080 Cost:  5.7529287 \n",
      "Prediction:\n",
      " [[149.22234]\n",
      " [186.3928 ]\n",
      " [180.27113]\n",
      " [193.8915 ]\n",
      " [145.81969]]\n",
      "1090 Cost:  5.72706 \n",
      "Prediction:\n",
      " [[149.23056]\n",
      " [186.38712]\n",
      " [180.27357]\n",
      " [193.89369]\n",
      " [145.81183]]\n",
      "1100 Cost:  5.701317 \n",
      "Prediction:\n",
      " [[149.23877]\n",
      " [186.38145]\n",
      " [180.27606]\n",
      " [193.89595]\n",
      " [145.80402]]\n",
      "1110 Cost:  5.675686 \n",
      "Prediction:\n",
      " [[149.24696]\n",
      " [186.37578]\n",
      " [180.27852]\n",
      " [193.89816]\n",
      " [145.7962 ]]\n",
      "1120 Cost:  5.650261 \n",
      "Prediction:\n",
      " [[149.25513]\n",
      " [186.37015]\n",
      " [180.28094]\n",
      " [193.90036]\n",
      " [145.78844]]\n",
      "1130 Cost:  5.624934 \n",
      "Prediction:\n",
      " [[149.26328]\n",
      " [186.36452]\n",
      " [180.2834 ]\n",
      " [193.90257]\n",
      " [145.78069]]\n",
      "1140 Cost:  5.5997047 \n",
      "Prediction:\n",
      " [[149.27141]\n",
      " [186.35892]\n",
      " [180.28583]\n",
      " [193.90479]\n",
      " [145.77293]]\n",
      "1150 Cost:  5.5746536 \n",
      "Prediction:\n",
      " [[149.2795 ]\n",
      " [186.3533 ]\n",
      " [180.28824]\n",
      " [193.90697]\n",
      " [145.76521]]\n",
      "1160 Cost:  5.5496817 \n",
      "Prediction:\n",
      " [[149.2876 ]\n",
      " [186.3477 ]\n",
      " [180.29065]\n",
      " [193.90918]\n",
      " [145.75752]]\n",
      "1170 Cost:  5.524913 \n",
      "Prediction:\n",
      " [[149.29564]\n",
      " [186.34216]\n",
      " [180.29308]\n",
      " [193.91138]\n",
      " [145.74985]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180 Cost:  5.500247 \n",
      "Prediction:\n",
      " [[149.30367]\n",
      " [186.3366 ]\n",
      " [180.29549]\n",
      " [193.91353]\n",
      " [145.74217]]\n",
      "1190 Cost:  5.475715 \n",
      "Prediction:\n",
      " [[149.31168]\n",
      " [186.33107]\n",
      " [180.29788]\n",
      " [193.91573]\n",
      " [145.73454]]\n",
      "1200 Cost:  5.4513 \n",
      "Prediction:\n",
      " [[149.31969]\n",
      " [186.32553]\n",
      " [180.30026]\n",
      " [193.91788]\n",
      " [145.72693]]\n",
      "1210 Cost:  5.4270434 \n",
      "Prediction:\n",
      " [[149.32765]\n",
      " [186.32005]\n",
      " [180.30266]\n",
      " [193.92004]\n",
      " [145.71933]]\n",
      "1220 Cost:  5.4028788 \n",
      "Prediction:\n",
      " [[149.33559]\n",
      " [186.31453]\n",
      " [180.30502]\n",
      " [193.92221]\n",
      " [145.71175]]\n",
      "1230 Cost:  5.3788843 \n",
      "Prediction:\n",
      " [[149.3435 ]\n",
      " [186.30907]\n",
      " [180.30739]\n",
      " [193.92436]\n",
      " [145.7042 ]]\n",
      "1240 Cost:  5.3549905 \n",
      "Prediction:\n",
      " [[149.35141]\n",
      " [186.30362]\n",
      " [180.30977]\n",
      " [193.92653]\n",
      " [145.69666]]\n",
      "1250 Cost:  5.331224 \n",
      "Prediction:\n",
      " [[149.3593 ]\n",
      " [186.29816]\n",
      " [180.31213]\n",
      " [193.92868]\n",
      " [145.68915]]\n",
      "1260 Cost:  5.3075933 \n",
      "Prediction:\n",
      " [[149.36714]\n",
      " [186.29272]\n",
      " [180.31447]\n",
      " [193.93082]\n",
      " [145.68164]]\n",
      "1270 Cost:  5.284095 \n",
      "Prediction:\n",
      " [[149.37497]\n",
      " [186.28732]\n",
      " [180.31682]\n",
      " [193.93294]\n",
      " [145.67415]]\n",
      "1280 Cost:  5.2607274 \n",
      "Prediction:\n",
      " [[149.38278]\n",
      " [186.28192]\n",
      " [180.31915]\n",
      " [193.93507]\n",
      " [145.6667 ]]\n",
      "1290 Cost:  5.237442 \n",
      "Prediction:\n",
      " [[149.39056]\n",
      " [186.27652]\n",
      " [180.32147]\n",
      " [193.9372 ]\n",
      " [145.65924]]\n",
      "1300 Cost:  5.2142916 \n",
      "Prediction:\n",
      " [[149.39835]\n",
      " [186.27115]\n",
      " [180.3238 ]\n",
      " [193.93933]\n",
      " [145.65182]]\n",
      "1310 Cost:  5.191278 \n",
      "Prediction:\n",
      " [[149.40608]\n",
      " [186.2658 ]\n",
      " [180.32611]\n",
      " [193.94144]\n",
      " [145.64441]]\n",
      "1320 Cost:  5.1683836 \n",
      "Prediction:\n",
      " [[149.41383]\n",
      " [186.26045]\n",
      " [180.32843]\n",
      " [193.94357]\n",
      " [145.63705]]\n",
      "1330 Cost:  5.145623 \n",
      "Prediction:\n",
      " [[149.42152]\n",
      " [186.25513]\n",
      " [180.33072]\n",
      " [193.94565]\n",
      " [145.62967]]\n",
      "1340 Cost:  5.122998 \n",
      "Prediction:\n",
      " [[149.42923]\n",
      " [186.24983]\n",
      " [180.33302]\n",
      " [193.94777]\n",
      " [145.62236]]\n",
      "1350 Cost:  5.100453 \n",
      "Prediction:\n",
      " [[149.43689]\n",
      " [186.24452]\n",
      " [180.33533]\n",
      " [193.94986]\n",
      " [145.61502]]\n",
      "1360 Cost:  5.0780563 \n",
      "Prediction:\n",
      " [[149.44453]\n",
      " [186.23926]\n",
      " [180.3376 ]\n",
      " [193.95197]\n",
      " [145.60773]]\n",
      "1370 Cost:  5.0557694 \n",
      "Prediction:\n",
      " [[149.45215]\n",
      " [186.23398]\n",
      " [180.33989]\n",
      " [193.95404]\n",
      " [145.60043]]\n",
      "1380 Cost:  5.033589 \n",
      "Prediction:\n",
      " [[149.45975]\n",
      " [186.22873]\n",
      " [180.34216]\n",
      " [193.95615]\n",
      " [145.59317]]\n",
      "1390 Cost:  5.011524 \n",
      "Prediction:\n",
      " [[149.46732]\n",
      " [186.22346]\n",
      " [180.3444 ]\n",
      " [193.9582 ]\n",
      " [145.5859 ]]\n",
      "1400 Cost:  4.98962 \n",
      "Prediction:\n",
      " [[149.47488]\n",
      " [186.21825]\n",
      " [180.34668]\n",
      " [193.96028]\n",
      " [145.5787 ]]\n",
      "1410 Cost:  4.9677763 \n",
      "Prediction:\n",
      " [[149.48242]\n",
      " [186.21304]\n",
      " [180.34894]\n",
      " [193.96237]\n",
      " [145.57149]]\n",
      "1420 Cost:  4.9460793 \n",
      "Prediction:\n",
      " [[149.48994]\n",
      " [186.20786]\n",
      " [180.35118]\n",
      " [193.96443]\n",
      " [145.5643 ]]\n",
      "1430 Cost:  4.924493 \n",
      "Prediction:\n",
      " [[149.49744]\n",
      " [186.20267]\n",
      " [180.35342]\n",
      " [193.96649]\n",
      " [145.55713]]\n",
      "1440 Cost:  4.903033 \n",
      "Prediction:\n",
      " [[149.5049 ]\n",
      " [186.1975 ]\n",
      " [180.35565]\n",
      " [193.96854]\n",
      " [145.54997]]\n",
      "1450 Cost:  4.881681 \n",
      "Prediction:\n",
      " [[149.51236]\n",
      " [186.19234]\n",
      " [180.35788]\n",
      " [193.97058]\n",
      " [145.54285]]\n",
      "1460 Cost:  4.8604326 \n",
      "Prediction:\n",
      " [[149.51979]\n",
      " [186.1872 ]\n",
      " [180.3601 ]\n",
      " [193.97264]\n",
      " [145.53574]]\n",
      "1470 Cost:  4.8392515 \n",
      "Prediction:\n",
      " [[149.5272 ]\n",
      " [186.18207]\n",
      " [180.36232]\n",
      " [193.97469]\n",
      " [145.52861]]\n",
      "1480 Cost:  4.818245 \n",
      "Prediction:\n",
      " [[149.5346 ]\n",
      " [186.17696]\n",
      " [180.36452]\n",
      " [193.97672]\n",
      " [145.52155]]\n",
      "1490 Cost:  4.797342 \n",
      "Prediction:\n",
      " [[149.54196]\n",
      " [186.17188]\n",
      " [180.36671]\n",
      " [193.97876]\n",
      " [145.51448]]\n",
      "1500 Cost:  4.7765512 \n",
      "Prediction:\n",
      " [[149.54932]\n",
      " [186.1668 ]\n",
      " [180.36893]\n",
      " [193.98079]\n",
      " [145.50745]]\n",
      "1510 Cost:  4.755864 \n",
      "Prediction:\n",
      " [[149.55664]\n",
      " [186.16171]\n",
      " [180.3711 ]\n",
      " [193.98279]\n",
      " [145.50041]]\n",
      "1520 Cost:  4.7352796 \n",
      "Prediction:\n",
      " [[149.56396]\n",
      " [186.15666]\n",
      " [180.3733 ]\n",
      " [193.98483]\n",
      " [145.49342]]\n",
      "1530 Cost:  4.7148504 \n",
      "Prediction:\n",
      " [[149.57124]\n",
      " [186.15164]\n",
      " [180.37547]\n",
      " [193.98682]\n",
      " [145.48643]]\n",
      "1540 Cost:  4.694467 \n",
      "Prediction:\n",
      " [[149.5785 ]\n",
      " [186.14658]\n",
      " [180.37764]\n",
      " [193.98883]\n",
      " [145.47946]]\n",
      "1550 Cost:  4.6742125 \n",
      "Prediction:\n",
      " [[149.58577]\n",
      " [186.14159]\n",
      " [180.37979]\n",
      " [193.99084]\n",
      " [145.47252]]\n",
      "1560 Cost:  4.65411 \n",
      "Prediction:\n",
      " [[149.593  ]\n",
      " [186.1366 ]\n",
      " [180.38196]\n",
      " [193.99283]\n",
      " [145.4656 ]]\n",
      "1570 Cost:  4.6340475 \n",
      "Prediction:\n",
      " [[149.6002 ]\n",
      " [186.13159]\n",
      " [180.38411]\n",
      " [193.99483]\n",
      " [145.45868]]\n",
      "1580 Cost:  4.61411 \n",
      "Prediction:\n",
      " [[149.6074 ]\n",
      " [186.12663]\n",
      " [180.38626]\n",
      " [193.99684]\n",
      " [145.4518 ]]\n",
      "1590 Cost:  4.5942726 \n",
      "Prediction:\n",
      " [[149.61455]\n",
      " [186.12164]\n",
      " [180.38838]\n",
      " [193.9988 ]\n",
      " [145.44489]]\n",
      "1600 Cost:  4.5745735 \n",
      "Prediction:\n",
      " [[149.6217 ]\n",
      " [186.11671]\n",
      " [180.39053]\n",
      " [194.0008 ]\n",
      " [145.43805]]\n",
      "1610 Cost:  4.554945 \n",
      "Prediction:\n",
      " [[149.62883]\n",
      " [186.11179]\n",
      " [180.39267]\n",
      " [194.00278]\n",
      " [145.4312 ]]\n",
      "1620 Cost:  4.5353956 \n",
      "Prediction:\n",
      " [[149.63596]\n",
      " [186.10686]\n",
      " [180.39479]\n",
      " [194.00478]\n",
      " [145.42438]]\n",
      "1630 Cost:  4.5160284 \n",
      "Prediction:\n",
      " [[149.64304]\n",
      " [186.10197]\n",
      " [180.3969 ]\n",
      " [194.00671]\n",
      " [145.41757]]\n",
      "1640 Cost:  4.496714 \n",
      "Prediction:\n",
      " [[149.65012]\n",
      " [186.09708]\n",
      " [180.39902]\n",
      " [194.0087 ]\n",
      " [145.4108 ]]\n",
      "1650 Cost:  4.4775314 \n",
      "Prediction:\n",
      " [[149.65715]\n",
      " [186.0922 ]\n",
      " [180.40111]\n",
      " [194.01064]\n",
      " [145.40402]]\n",
      "1660 Cost:  4.4584103 \n",
      "Prediction:\n",
      " [[149.66418]\n",
      " [186.08734]\n",
      " [180.4032 ]\n",
      " [194.0126 ]\n",
      " [145.39726]]\n",
      "1670 Cost:  4.439392 \n",
      "Prediction:\n",
      " [[149.6712 ]\n",
      " [186.08247]\n",
      " [180.40529]\n",
      " [194.01454]\n",
      " [145.39052]]\n",
      "1680 Cost:  4.4205194 \n",
      "Prediction:\n",
      " [[149.67819]\n",
      " [186.07764]\n",
      " [180.40738]\n",
      " [194.01646]\n",
      " [145.3838 ]]\n",
      "1690 Cost:  4.401726 \n",
      "Prediction:\n",
      " [[149.68515]\n",
      " [186.07281]\n",
      " [180.40945]\n",
      " [194.01842]\n",
      " [145.3771 ]]\n",
      "1700 Cost:  4.3830056 \n",
      "Prediction:\n",
      " [[149.69212]\n",
      " [186.06801]\n",
      " [180.41154]\n",
      " [194.02039]\n",
      " [145.37044]]\n",
      "1710 Cost:  4.364398 \n",
      "Prediction:\n",
      " [[149.69905]\n",
      " [186.0632 ]\n",
      " [180.41359]\n",
      " [194.0223 ]\n",
      " [145.36375]]\n",
      "1720 Cost:  4.345938 \n",
      "Prediction:\n",
      " [[149.70596]\n",
      " [186.05844]\n",
      " [180.41568]\n",
      " [194.02423]\n",
      " [145.35713]]\n",
      "1730 Cost:  4.3274994 \n",
      "Prediction:\n",
      " [[149.71284]\n",
      " [186.05363]\n",
      " [180.41772]\n",
      " [194.02615]\n",
      " [145.35048]]\n",
      "1740 Cost:  4.309224 \n",
      "Prediction:\n",
      " [[149.71973]\n",
      " [186.0489 ]\n",
      " [180.41977]\n",
      " [194.02808]\n",
      " [145.34389]]\n",
      "1750 Cost:  4.291001 \n",
      "Prediction:\n",
      " [[149.72658]\n",
      " [186.04414]\n",
      " [180.4218 ]\n",
      " [194.02998]\n",
      " [145.33728]]\n",
      "1760 Cost:  4.2728987 \n",
      "Prediction:\n",
      " [[149.73343]\n",
      " [186.03943]\n",
      " [180.42386]\n",
      " [194.0319 ]\n",
      " [145.33072]]\n",
      "1770 Cost:  4.25487 \n",
      "Prediction:\n",
      " [[149.74023]\n",
      " [186.03468]\n",
      " [180.42587]\n",
      " [194.0338 ]\n",
      " [145.32414]]\n",
      "1780 Cost:  4.236953 \n",
      "Prediction:\n",
      " [[149.74702]\n",
      " [186.02998]\n",
      " [180.4279 ]\n",
      " [194.0357 ]\n",
      " [145.3176 ]]\n",
      "1790 Cost:  4.2191157 \n",
      "Prediction:\n",
      " [[149.75383]\n",
      " [186.0253 ]\n",
      " [180.42993]\n",
      " [194.03761]\n",
      " [145.31108]]\n",
      "1800 Cost:  4.2014 \n",
      "Prediction:\n",
      " [[149.76059]\n",
      " [186.02061]\n",
      " [180.43196]\n",
      " [194.0395 ]\n",
      " [145.30458]]\n",
      "1810 Cost:  4.183751 \n",
      "Prediction:\n",
      " [[149.76733]\n",
      " [186.01596]\n",
      " [180.43396]\n",
      " [194.0414 ]\n",
      " [145.29808]]\n",
      "1820 Cost:  4.166202 \n",
      "Prediction:\n",
      " [[149.77405]\n",
      " [186.01129]\n",
      " [180.43596]\n",
      " [194.04327]\n",
      " [145.2916 ]]\n",
      "1830 Cost:  4.148739 \n",
      "Prediction:\n",
      " [[149.78078]\n",
      " [186.00665]\n",
      " [180.43796]\n",
      " [194.04515]\n",
      " [145.28514]]\n",
      "1840 Cost:  4.131402 \n",
      "Prediction:\n",
      " [[149.78745]\n",
      " [186.00203]\n",
      " [180.43996]\n",
      " [194.04703]\n",
      " [145.2787 ]]\n",
      "1850 Cost:  4.114115 \n",
      "Prediction:\n",
      " [[149.79413]\n",
      " [185.9974 ]\n",
      " [180.44194]\n",
      " [194.0489 ]\n",
      " [145.27228]]\n",
      "1860 Cost:  4.0969496 \n",
      "Prediction:\n",
      " [[149.80077]\n",
      " [185.9928 ]\n",
      " [180.44391]\n",
      " [194.05077]\n",
      " [145.26587]]\n",
      "1870 Cost:  4.0798683 \n",
      "Prediction:\n",
      " [[149.8074 ]\n",
      " [185.9882 ]\n",
      " [180.4459 ]\n",
      " [194.05264]\n",
      " [145.25949]]\n",
      "1880 Cost:  4.0628586 \n",
      "Prediction:\n",
      " [[149.81401]\n",
      " [185.98364]\n",
      " [180.44788]\n",
      " [194.0545 ]\n",
      " [145.2531 ]]\n",
      "1890 Cost:  4.04595 \n",
      "Prediction:\n",
      " [[149.82062]\n",
      " [185.97908]\n",
      " [180.44983]\n",
      " [194.05637]\n",
      " [145.24675]]\n",
      "1900 Cost:  4.0291395 \n",
      "Prediction:\n",
      " [[149.8272 ]\n",
      " [185.97452]\n",
      " [180.4518 ]\n",
      " [194.0582 ]\n",
      " [145.2404 ]]\n",
      "1910 Cost:  4.012422 \n",
      "Prediction:\n",
      " [[149.83376]\n",
      " [185.96997]\n",
      " [180.45374]\n",
      " [194.06006]\n",
      " [145.2341 ]]\n",
      "1920 Cost:  3.9957855 \n",
      "Prediction:\n",
      " [[149.84029]\n",
      " [185.96545]\n",
      " [180.4557 ]\n",
      " [194.0619 ]\n",
      " [145.22778]]\n",
      "1930 Cost:  3.9792237 \n",
      "Prediction:\n",
      " [[149.8468 ]\n",
      " [185.96092]\n",
      " [180.45763]\n",
      " [194.06374]\n",
      " [145.22148]]\n",
      "1940 Cost:  3.962775 \n",
      "Prediction:\n",
      " [[149.85332]\n",
      " [185.95644]\n",
      " [180.45958]\n",
      " [194.06558]\n",
      " [145.21523]]\n",
      "1950 Cost:  3.9464011 \n",
      "Prediction:\n",
      " [[149.8598 ]\n",
      " [185.95193]\n",
      " [180.4615 ]\n",
      " [194.06738]\n",
      " [145.20895]]\n",
      "1960 Cost:  3.9301014 \n",
      "Prediction:\n",
      " [[149.86627]\n",
      " [185.94746]\n",
      " [180.46344]\n",
      " [194.06923]\n",
      " [145.20271]]\n",
      "1970 Cost:  3.9138885 \n",
      "Prediction:\n",
      " [[149.87271]\n",
      " [185.943  ]\n",
      " [180.46535]\n",
      " [194.07104]\n",
      " [145.19647]]\n",
      "1980 Cost:  3.897775 \n",
      "Prediction:\n",
      " [[149.87917]\n",
      " [185.93855]\n",
      " [180.46727]\n",
      " [194.07289]\n",
      " [145.19029]]\n",
      "1990 Cost:  3.881749 \n",
      "Prediction:\n",
      " [[149.88556]\n",
      " [185.93411]\n",
      " [180.46918]\n",
      " [194.07469]\n",
      " [145.18408]]\n",
      "2000 Cost:  3.8658013 \n",
      "Prediction:\n",
      " [[149.89195]\n",
      " [185.92967]\n",
      " [180.47107]\n",
      " [194.07649]\n",
      " [145.1779 ]]\n"
     ]
    }
   ],
   "source": [
    "x_data=[[73., 80., 75.], [93., 88., 93.], [89., 91., 90.], [96., 98., 100.], [73., 66., 70.]]\n",
    "y_data=[[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([3,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X,w) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                  feed_dict={X: x_data, Y: y_data})\n",
    "    if step %10 ==0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab 04-2 파일에서 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 2 but is rank 0 for 'MatMul_7' (op: 'MatMul') with input shapes: [?,3], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1606\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1607\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 2 but is rank 0 for 'MatMul_7' (op: 'MatMul') with input shapes: [?,3], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-ecb937091761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bias'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2753\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2754\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6134\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   6135\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6136\u001b[0;31m                   name=name)\n\u001b[0m\u001b[1;32m   6137\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6138\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3357\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m   def _create_op_internal(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3426\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1770\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1771\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 2 but is rank 0 for 'MatMul_7' (op: 'MatMul') with input shapes: [?,3], []."
     ]
    }
   ],
   "source": [
    "filename_queue = tf.train.string_input_producer(['data-01-test-score.csv'], shuffle = False, name = 'filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.], [0.],[0.],[0.]]\n",
    "xy = tf.decode_csv(value, record_defaults = record_defaults)\n",
    "\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size = 10)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([3,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean =(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess = sess, coord = coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], \n",
    "                                   feed_dict = {X: x_batch, Y: y_batch} )\n",
    "    if step % 10 == 0 :\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "        \n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
