{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  MNIST test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dataset \n",
    "import torchvision.transforms as transforms \n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: gpu\") if torch.cuda.is_available() else print(\"device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "epochs = 100\n",
    "display_step = 10\n",
    "batch_size = 32\n",
    "\n",
    "activation = nn.ReLU()\n",
    "max_pool = nn.MaxPool2d(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_data):  60000\n",
      "len(test_data):  10000\n",
      "data tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "data shape:  torch.Size([1, 28, 28])\n",
      "label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([32, 1, 28, 28])\n",
      "label: tensor([8, 6, 7, 8, 3, 9, 9, 4, 1, 7, 7, 0, 8, 6, 7, 5, 3, 0, 1, 4, 1, 9, 4, 9,\n",
      "        4, 2, 5, 6, 9, 5, 4, 8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "train_data = dataset.MNIST(\"./\", train = True, transform = transforms.ToTensor(), target_transform = None, download = True)\n",
    "test_data = dataset.MNIST(\"./\", train = False, transform = transforms.ToTensor(), target_transform = None, download = True)\n",
    "\n",
    "# check the data\n",
    "print('len(train_data): ', len(train_data))\n",
    "print('len(test_data): ', len(test_data))\n",
    "\n",
    "x_train, y_train = train_data[0]\n",
    "print('data', x_train)\n",
    "print('data shape: ', x_train.shape)\n",
    "print('label: ', y_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()\n",
    "\n",
    "# Pre-process (batch, shuffle)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True, num_workers = 1, drop_last = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = True, num_workers = 1, drop_last = True)\n",
    "\n",
    "# check the data \n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_target) = next(examples)\n",
    "\n",
    "print('data shape:', example_data.shape)\n",
    "print('label:', example_target)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(example_data[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model & Optimization and Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-29a6bfdbbbcb>:29: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # for initializing nn.Module (parent class)\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5), # number of input channel, number of output channel, kernel size   \n",
    "            nn.BatchNorm2d(16),\n",
    "            activation,# we can set stride size and padding size. if we do not set the these parameters, default value is 1, 0.\n",
    "            max_pool,\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation,\n",
    "            max_pool\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 5 * 5, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            activation,\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        extracted_feature = self.feature_extraction(x) # [32, 64, 5, 5]\n",
    "        flatten = extracted_feature.view(batch_size, -1) # [32, (64 * 5 * 5)]\n",
    "        result = self.classifier(flatten)\n",
    "        return result\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "model = CNN()\n",
    "model.apply(init_weights)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch loss: 0.16308337450027466\n",
      "10 epoch loss: 0.054897285997867584\n",
      "20 epoch loss: 0.0011760263005271554\n",
      "30 epoch loss: 1.3090208085486665e-05\n",
      "40 epoch loss: 1.5241723303915933e-05\n",
      "50 epoch loss: 6.160935299703851e-05\n",
      "60 epoch loss: 0.0008838378125801682\n",
      "70 epoch loss: 0.0011691274121403694\n",
      "80 epoch loss: 0.00027722225058823824\n",
      "90 epoch loss: 1.189053728012368e-05\n"
     ]
    }
   ],
   "source": [
    "loss_array = []\n",
    "\n",
    "# train the model\n",
    "for i in range(epochs):\n",
    "    for index, [data, label] in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(data)\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i % display_step == 0:\n",
    "        print('{} epoch loss: {}'.format(i,loss))\n",
    "        loss_array.append(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST test_accuracy : 0.9938902258872986\n"
     ]
    }
   ],
   "source": [
    "#test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "prediction_list = []\n",
    "label_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, [data, label] in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        output = model.forward(data)\n",
    "        _, prediction_index = torch.max(output, 1)\n",
    "        \n",
    "        prediction_list.append(prediction_index)\n",
    "        label_list.append(label)\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += (prediction_index == label).sum().float()\n",
    "\n",
    "    print(\"MNIST test_accuracy : {}\".format(correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
