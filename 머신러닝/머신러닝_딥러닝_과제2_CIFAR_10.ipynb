{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "머신러닝_딥러닝 과제2_CIFAR-10",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ync0vc9tUXNx",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR -10 accuracy test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LE-e6dEUa7P",
        "colab_type": "text"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj366knn5ZD8",
        "colab_type": "code",
        "outputId": "2e9b5c62-0abe-415b-86a8-b9458d4c40ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dataset \n",
        "import torchvision.transforms as transforms \n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device: gpu\") if torch.cuda.is_available() else print(\"device: cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: gpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94_zVO9uUfeI",
        "colab_type": "text"
      },
      "source": [
        "# Hyper parameter setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGHceDILULnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 1e-3\n",
        "epochs = 100\n",
        "display_step = 10\n",
        "batch_size = 32\n",
        "\n",
        "activation = nn.ReLU()\n",
        "max_pool = nn.MaxPool2d(2,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n5WhVwAUhWu",
        "colab_type": "text"
      },
      "source": [
        "# Load data & Pre-process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq6j5JnbUPG-",
        "colab_type": "code",
        "outputId": "adc8fe0e-af0f-4391-c010-f6f4ad4b9882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# load data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_data = dataset.CIFAR10(\"./\", train = True, transform = transform_train, target_transform = None, download = True)\n",
        "test_data = dataset.CIFAR10(\"./\", train = False, transform = transform_test, target_transform = None, download = True)\n",
        "# check the data\n",
        "print('len(train_data): ', len(train_data))\n",
        "print('len(test_data): ', len(test_data))\n",
        "\n",
        "x_train, y_train = train_data[0]\n",
        "x_train = np.transpose(x_train, (1,2,0))\n",
        "# 3 x 32 x 32에서 32 x 32 x 3으로 변환\n",
        "\n",
        "print('data', x_train)\n",
        "print('data shape: ', x_train.shape)\n",
        "print('label: ', y_train)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(x_train[0])\n",
        "plt.show()\n",
        "\n",
        "# Pre-process (batch, shuffle)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True, num_workers = 1, drop_last = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = True, num_workers = 1, drop_last = True)\n",
        "\n",
        "# check the data \n",
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_target) = next(examples)\n",
        "\n",
        "print('data shape:', example_data.shape)\n",
        "print('label:', example_target)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(np.transpose(example_data[0], (1,2,0)))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "len(train_data):  50000\n",
            "len(test_data):  10000\n",
            "data tensor([[[-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         ...,\n",
            "         [-0.1610, -0.9629, -1.5385],\n",
            "         [-0.1998, -1.0416, -1.5776],\n",
            "         [-0.3743, -1.1792, -1.6751]],\n",
            "\n",
            "        [[-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         ...,\n",
            "         [-0.0835, -0.9039, -1.5190],\n",
            "         [-0.0253, -0.9039, -1.5190],\n",
            "         [ 0.0328, -0.8646, -1.4605]],\n",
            "\n",
            "        [[-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         ...,\n",
            "         [ 0.1104, -0.7662, -1.4020],\n",
            "         [ 0.2073, -0.6876, -1.3434],\n",
            "         [ 0.0716, -0.8056, -1.4800]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         ...,\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214]],\n",
            "\n",
            "        [[-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         ...,\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214]],\n",
            "\n",
            "        [[-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         ...,\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214],\n",
            "         [-2.4291, -2.4183, -2.2214]]])\n",
            "data shape:  torch.Size([32, 32, 3])\n",
            "label:  6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD4AAAD5CAYAAAB/LIZIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAKA0lEQVR4nO2dbYxcVRnHf/+Z3e1ud5e+QyuttNRGqSZUUxGUDxXENMSIJoTAB0IMsRJt1MQvBhMhxg+YKIREo0Eh1kRtsYo0BF8INiEGxZbSFlrUlAahpa/Q0i7ddndnHj/cO82wnDN7Z+7Mbafn/JLJ3jnv/z137rn3nOc+R2ZGiJTOdQPOFVF4aEThoRGs8J48mSWtBh4EysAvzOy+Run7NM36GWy+nl53M0cnTjJWHVXTBZJDuKQy8BPgBmAfsEXSJjPb7cvTzyCf0PXNN3LefGf4s0c2NF1WjTyn+lXAHjPba2ZjwHrgphzlFUoe4ZcCr9d935eGdQW5fuNZkLQGWAPQz/ROV5eZPD2+H1hU931hGvYuzOwhM1tpZit7mZajuvaSR/gWYJmkJZL6gFuBTe1pVudp+VQ3swlJa4G/kAxnj5jZrra1rMPk+o2b2ZPAk21qS6EEe+cWhYdGFB4aUXhoROGhEYWHRsefx+sZX9rPwfuvcMaNvTDLm2/oNfcy18TjrT/mBtvjUXhoROGhEazwQoezuf0jfGnZP5xxPz61yptv9Ix7Wrra23pbgu3xKDw0ovDQCFZ4XouIV4GTQAWYMLOVjSurMrs84owrlarefNWyO9xasoWotSU/nzazo20op1CCPdXzCjfgr5KeTw0Auoa8p/q1ZrZf0sXAU5L+bWbP1Ceot4iY876+nNW1j1w9bmb707+HgcdIDIImpzlrETE8K8fNdZtpWbikQUnDtWPgs8BL7WpYp8lzql8CPCapVs5vzOzPDStThYt7Tjrj+voq3nz+ga518piC7AWubGNbCiUOZ6ERhYdGsMILnWzsVYX55RPOuL6eCW++0zmewnwE2+NReGhE4aFR6FW9QokT5rZiGJvwN0We5xfleB842B6PwkMjCg+NYIUXOpxVTZyquoczNRibqp7uybOEFGyPR+GhEYWHRrDCpxzOJD0CfA44bGYfScNmAxuAxcCrwC1mdmyqssath/3jbrv006P+ldTppzxty7G2lKXHfwmsnhT2beBpM1sGPJ1+7yqmFJ6ud781KfgmYF16vA74Qpvb1XFa/Y1fYmYH0uODJCunXUXui5slftG895uS1kjaKmnryWPjeatrG60KPyRpAUD697Av4YVmEbEJuCM9vgN4vD3NKY4sw9lvgVXAXEn7gHuA+4BHJd0J/A+4JUtlfRpncd8RZ9zw0Kg33+iw217dcvxQpxRuZrd5opr3XXQeEeydWxQeGlF4aBRsEVFlvsdefdZ0/3A2MuC5MczRbcH2eBQeGlF4aAQrvNDhTCRDWrP41sjyeIYPtsej8NCIwkOjWJdHlDhYcbsZPzridz/eO+K+rHd6CemCJAoPjSg8NIIV3qpFxL3Al4HaetDdqefthoxW+9gxepkz7sQxv7f9i9zv4Xrt2LPQqkUEwANmtiL9dJ2r8VYtIrqePL/xtZJ2SnpEkt/T5HlKq8J/CiwFVgAHgB/5EtZbRIy81eUWEWZ2yMwqZlYFfo7DN0Rd2rMWEUOzu9wiomYGkvJFusg3RI1WLSJWSVpBMu31KvCVTJWpwiW9x51xvQP+n8HYDLeNu3lcIWVqy1QJPBYRD7de5flBsHduUXhoROGhUehk4+lqL7tGFzrjxo/1e/MNep4USh1+OrsgicJDIwoPjWCFFzqcAZRasWPwrZFF5xjNE4WHRhQeGoVe1ftL41wx8J7tiwEoDfvn3CoD7mbmeQsp2B6PwkMjCg+NYIVnWUJaBPyK5OV4Ax4yswdb8RPRpwne3+OeQJs+eMabz8oDnsZN1Xo/WXp8AviWmS0Hrga+Jmk5Xe4nIotFxAEz25YenwReBi6ly/1ENPUbl7QY+CjwHF3uJyKzcElDwO+Bb5rZuxwoN/ITUW8RcfzNHBPhbSaTcEm9JKJ/bWZ/SIMz+Ymot4iYOSfHgnabmVK4kt0hHgZeNrP766K62k9ElqezTwG3Ay9K2p6G3U0LfiKGJK7ud/f6FfMOefO9MHuGM9y3OVQWslhE/B3/iNm1fiKCvXOLwkMjCg+NQicbXxsf5OtvfNwZt+Wlpd58s/e6w8v+B7opCbbHo/DQiMJDI1jhxW4XYuL4uHviUBX/zGG1xxMX/as3TxQeGlF4aBR6Vb+ofJrPzNrtjNu2YJE33+kjnjm3HK+xBdvjUXhoROGhEazwPBYR99Kkn4gJSrxVGXLGjZ7y75ox2AEfEVnG8ZpFxDZJw8Dzkp5K4x4wsx+2Xv25I8va2QESrwCY2UlJNYuIriaPRQR0sZ+IPBYRmfxE1FtEvNNtPiJcFhFZ/UTUW0QMdpOPCJ9FRLf7ichjEXFbs34iRiam8ewx91JRaZ//pdqBI+7XjUr+vdqnJI9FRNe5Oaon2Du3KDw0ovDQKHSy0RBjFXeVPaON1oPyOBR3E2yPR+GhEYWHRrDCCx3OppUmWDz0pjPuxVlLvPkqb7iHurjjfAtE4aERhYdGsMILHc7KqjKjx713oZX9T2Ca8GwXEl0eNU8UHhpReGhksYjoB54BpqXpN5rZPZKWAOuBOcDzwO1mNtaorKqVOFVxWz6UzvifOPL4X/WWmSHNGeA6M7uSZEl4taSrgR+QWER8ADgG3Nn+5nWOLD4izMxqGwr3ph8DrgM2puEXpo8ISeV0pfQw8BTwCnDczGrrlfvoMvOQTMJTA4AVwEISA4APZa2g3iLi1PEcrwa2maau6mZ2HNgMXAPMlFS7OC4EnI7a6i0ips9074VwLshiETFP0sz0eAC4gcQXzGbg5jTZBekjYgGwTlKZ5B/1qJk9IWk3sF7S94EXyLChxOlqD6+MzHU35B1/H/SMusezPHsaZrGI2Eli4jU5fC8NNoY53wn2zi0KD40oPDSUOOYqqDLpCIl7JIC5wNGcRX7QzIZbyVisKYjZvNqxpK1mtjJPeZK2tpo32FM9Cj8HPHQuyyj04nY+EU/1TiFptaT/SNoj6T2+WyVNk7QhjX8ufe+lPn6RpM2SdkvaJekbjjJWSXpb0vb0890pG2ZmHfsAZZJpqsuBPmAHsHxSmq8CP0uPbwU2TIpfAHwsPR4G/usoYxXwRDNt63SPXwXsMbO96dTzehJHtvXUO7bdCFyfvg4CNHSIm4tOC78UeL3uu2tS8myadPLybZK5+vfgeP2rnmsk7ZD0J0kfnqphhe+M0yqNHOIC24DLzGxE0o3AH4FljcrrdI/vB+p9ILgmJc+mSScvZwDvsgnzOMQ9i5mdqM39p++39kpyz3GldFr4FmCZpCWS+kguXpsmpal3bHsz8Deru7lo4BCXujTza9cFSVeR6HIb1NXo5FU9bf+NJFfiV4DvpGHfAz6fHvcDvwP2AP8CLp+U/1qSlZudwPb0cyNwF3BXmmYtsItk1Pgn8Mmp2hXv3EIjCg+NKDw0ovDQCFb4/wHhiT27OL+jBAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "data shape: torch.Size([32, 3, 32, 32])\n",
            "label: tensor([6, 1, 1, 9, 4, 2, 2, 8, 5, 1, 8, 1, 5, 9, 5, 9, 4, 0, 4, 1, 6, 6, 5, 4,\n",
            "        0, 5, 1, 9, 6, 4, 0, 8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gPLBdjvUnE0",
        "colab_type": "text"
      },
      "source": [
        "# Model & Optimization and Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77zez2uR5mTP",
        "colab_type": "code",
        "outputId": "cde38078-eab2-4cfd-8dbd-16cab2000d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__() \n",
        "        self.feature_extraction = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            activation,\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3),\n",
        "            nn.BatchNorm2d(128),\n",
        "            activation,\n",
        "            max_pool,\n",
        "            nn.Dropout(0.3),\n",
        "            \n",
        "            nn.Conv2d(128, 256, 3),\n",
        "            nn.BatchNorm2d(256),\n",
        "            activation,\n",
        "            max_pool,\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(256, 512, 3),\n",
        "            nn.BatchNorm2d(512),\n",
        "            activation,\n",
        "            max_pool,\n",
        "            nn.Dropout(0.2)\n",
        "\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 2 * 2, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            activation,\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            activation,\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 10)\n",
        "            \n",
        "        )\n",
        "    def forward(self, x):\n",
        "        extracted_feature = self.feature_extraction(x) # [32, 256, 6, 6]\n",
        "        flatten = extracted_feature.view(batch_size, -1) # [32, 256 * 6 * 6]\n",
        "        result = self.classifier(flatten)\n",
        "        return result\n",
        "    \n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "        \n",
        "model = CNN()\n",
        "model.apply(init_weights)\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of6dnwoXUq8S",
        "colab_type": "text"
      },
      "source": [
        "# Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an4RLJ0b5tQx",
        "colab_type": "code",
        "outputId": "f1c6fb7c-ba05-4d65-f8d7-12609c9e82b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "loss_array = []\n",
        "\n",
        "# train the model\n",
        "for i in range(epochs):\n",
        "    for index, [data, label] in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(data)\n",
        "        loss = loss_function(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    if i % display_step == 0:\n",
        "        print('{} epoch loss: {}'.format(i,loss))\n",
        "        loss_array.append(loss.cpu().detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60 epoch loss: 0.4304533004760742\n",
            "70 epoch loss: 0.2155846804380417\n",
            "80 epoch loss: 0.1945393681526184\n",
            "90 epoch loss: 0.2991451621055603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsTLJm2acZ9J",
        "colab_type": "code",
        "outputId": "bb209750-9664-4ce5-84c1-3a7108a30283",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#test the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "prediction_list = []\n",
        "label_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for index, [data, label] in enumerate(test_loader):\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "        \n",
        "        output = model.forward(data)\n",
        "        _, prediction_index = torch.max(output, 1)\n",
        "        \n",
        "        prediction_list.append(prediction_index)\n",
        "        label_list.append(label)\n",
        "        \n",
        "        total += label.size(0)\n",
        "        correct += (prediction_index == label).sum().float()\n",
        "\n",
        "    print(\"CIFAR10 test_accuracy : {}\".format(correct/total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CIFAR10 test_accuracy : 0.9108573794364929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qisq7q0Z9xI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}