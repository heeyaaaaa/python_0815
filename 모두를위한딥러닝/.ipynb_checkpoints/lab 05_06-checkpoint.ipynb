{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab 05 Logistic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W)+b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.2017071\n",
      "200 0.52510285\n",
      "400 0.4843136\n",
      "600 0.4577388\n",
      "800 0.4374772\n",
      "1000 0.42044613\n",
      "1200 0.40531\n",
      "1400 0.39143857\n",
      "1600 0.37851164\n",
      "1800 0.36635372\n",
      "2000 0.3548608\n",
      "2200 0.3439653\n",
      "2400 0.3336185\n",
      "2600 0.3237823\n",
      "2800 0.31442443\n",
      "3000 0.30551672\n",
      "3200 0.29703292\n",
      "3400 0.28894892\n",
      "3600 0.2812421\n",
      "3800 0.27389097\n",
      "4000 0.26687565\n",
      "4200 0.26017705\n",
      "4400 0.25377718\n",
      "4600 0.24765909\n",
      "4800 0.24180704\n",
      "5000 0.23620622\n",
      "5200 0.23084229\n",
      "5400 0.22570239\n",
      "5600 0.22077404\n",
      "5800 0.21604566\n",
      "6000 0.21150641\n",
      "6200 0.20714606\n",
      "6400 0.20295513\n",
      "6600 0.19892456\n",
      "6800 0.19504623\n",
      "7000 0.19131194\n",
      "7200 0.18771438\n",
      "7400 0.18424678\n",
      "7600 0.1809024\n",
      "7800 0.17767529\n",
      "8000 0.17455964\n",
      "8200 0.17155005\n",
      "8400 0.16864143\n",
      "8600 0.16582902\n",
      "8800 0.16310827\n",
      "9000 0.16047502\n",
      "9200 0.15792519\n",
      "9400 0.15545504\n",
      "9600 0.15306102\n",
      "9800 0.15073968\n",
      "10000 0.14848809\n",
      "\n",
      "Hypothesis:  [[0.03031754]\n",
      " [0.15826975]\n",
      " [0.3028389 ]\n",
      " [0.7823103 ]\n",
      " [0.94015867]\n",
      " [0.9803649 ]] \n",
      "Correct(Y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost,train], feed_dict = {X: x_data, Y:y_data})\n",
    "        if step%200 ==0:\n",
    "            print(step, cost_val)\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict = {X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect(Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('DeepLearningZeroToAll-master/data-03-diabetes.csv', delimiter = ',', dtype = np.float32)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0775934\n",
      "200 0.7388337\n",
      "400 0.67895454\n",
      "600 0.65681976\n",
      "800 0.6412197\n",
      "1000 0.6277597\n",
      "1200 0.61566365\n",
      "1400 0.6047108\n",
      "1600 0.594776\n",
      "1800 0.58575666\n",
      "2000 0.57756054\n",
      "2200 0.57010436\n",
      "2400 0.5633129\n",
      "2600 0.55711824\n",
      "2800 0.5514596\n",
      "3000 0.54628295\n",
      "3200 0.54153967\n",
      "3400 0.5371867\n",
      "3600 0.53318566\n",
      "3800 0.5295024\n",
      "4000 0.52610654\n",
      "4200 0.5229708\n",
      "4400 0.5200711\n",
      "4600 0.5173859\n",
      "4800 0.5148957\n",
      "5000 0.51258326\n",
      "5200 0.51043314\n",
      "5400 0.5084313\n",
      "5600 0.5065653\n",
      "5800 0.5048237\n",
      "6000 0.5031965\n",
      "6200 0.50167435\n",
      "6400 0.50024897\n",
      "6600 0.49891287\n",
      "6800 0.49765903\n",
      "7000 0.4964814\n",
      "7200 0.49537408\n",
      "7400 0.49433202\n",
      "7600 0.49335048\n",
      "7800 0.4924251\n",
      "8000 0.49155203\n",
      "8200 0.49072748\n",
      "8400 0.4899482\n",
      "8600 0.4892112\n",
      "8800 0.4885135\n",
      "9000 0.48785263\n",
      "9200 0.4872262\n",
      "9400 0.48663196\n",
      "9600 0.48606795\n",
      "9800 0.48553205\n",
      "10000 0.48502275\n",
      "\n",
      "Hypothesis:  [[0.39136222]\n",
      " [0.91613823]\n",
      " [0.19013086]\n",
      " [0.93820715]\n",
      " [0.13448396]\n",
      " [0.7409643 ]\n",
      " [0.9360809 ]\n",
      " [0.599184  ]\n",
      " [0.23624772]\n",
      " [0.5377309 ]\n",
      " [0.7292745 ]\n",
      " [0.17987639]\n",
      " [0.19843948]\n",
      " [0.24976274]\n",
      " [0.70926094]\n",
      " [0.50278896]\n",
      " [0.7198186 ]\n",
      " [0.8530855 ]\n",
      " [0.81694895]\n",
      " [0.61094135]\n",
      " [0.6629013 ]\n",
      " [0.11883423]\n",
      " [0.6622792 ]\n",
      " [0.6864497 ]\n",
      " [0.37844944]\n",
      " [0.92977464]\n",
      " [0.5499333 ]\n",
      " [0.6508707 ]\n",
      " [0.69013274]\n",
      " [0.4274179 ]\n",
      " [0.95011675]\n",
      " [0.8596236 ]\n",
      " [0.5670785 ]\n",
      " [0.7824529 ]\n",
      " [0.36584607]\n",
      " [0.6265463 ]\n",
      " [0.82095873]\n",
      " [0.4859457 ]\n",
      " [0.4822844 ]\n",
      " [0.37587917]\n",
      " [0.82756984]\n",
      " [0.19619754]\n",
      " [0.37502813]\n",
      " [0.05281091]\n",
      " [0.53429025]\n",
      " [0.92460465]\n",
      " [0.72221094]\n",
      " [0.7047202 ]\n",
      " [0.9341872 ]\n",
      " [0.9227125 ]\n",
      " [0.92722404]\n",
      " [0.24318776]\n",
      " [0.33529818]\n",
      " [0.95568395]\n",
      " [0.22229668]\n",
      " [0.50494915]\n",
      " [0.11222339]\n",
      " [0.7424444 ]\n",
      " [0.8514637 ]\n",
      " [0.4963602 ]\n",
      " [0.9324992 ]\n",
      " [0.67705035]\n",
      " [0.64286   ]\n",
      " [0.8508706 ]\n",
      " [0.59061694]\n",
      " [0.5755546 ]\n",
      " [0.95254445]\n",
      " [0.7180811 ]\n",
      " [0.8481304 ]\n",
      " [0.6600425 ]\n",
      " [0.29349422]\n",
      " [0.7575923 ]\n",
      " [0.9171822 ]\n",
      " [0.91838384]\n",
      " [0.870147  ]\n",
      " [0.8000058 ]\n",
      " [0.44295514]\n",
      " [0.85747665]\n",
      " [0.8843764 ]\n",
      " [0.91517115]\n",
      " [0.85938156]\n",
      " [0.81660855]\n",
      " [0.44601724]\n",
      " [0.8117584 ]\n",
      " [0.5350063 ]\n",
      " [0.88378453]\n",
      " [0.45152608]\n",
      " [0.8966172 ]\n",
      " [0.91638315]\n",
      " [0.7847555 ]\n",
      " [0.8356873 ]\n",
      " [0.61163116]\n",
      " [0.6982597 ]\n",
      " [0.59511334]\n",
      " [0.9026284 ]\n",
      " [0.9715862 ]\n",
      " [0.88433015]\n",
      " [0.65703547]\n",
      " [0.22842756]\n",
      " [0.62428   ]\n",
      " [0.60031277]\n",
      " [0.95949376]\n",
      " [0.7511904 ]\n",
      " [0.71971047]\n",
      " [0.8913211 ]\n",
      " [0.67822367]\n",
      " [0.9220369 ]\n",
      " [0.8493685 ]\n",
      " [0.52342516]\n",
      " [0.33792448]\n",
      " [0.9355264 ]\n",
      " [0.86283743]\n",
      " [0.40416467]\n",
      " [0.4210547 ]\n",
      " [0.6296448 ]\n",
      " [0.8090036 ]\n",
      " [0.85736793]\n",
      " [0.91893065]\n",
      " [0.17280433]\n",
      " [0.7274037 ]\n",
      " [0.8604553 ]\n",
      " [0.5915537 ]\n",
      " [0.63716155]\n",
      " [0.8189372 ]\n",
      " [0.7280364 ]\n",
      " [0.839962  ]\n",
      " [0.8275949 ]\n",
      " [0.5688127 ]\n",
      " [0.5232063 ]\n",
      " [0.3575021 ]\n",
      " [0.43707684]\n",
      " [0.7811407 ]\n",
      " [0.92611593]\n",
      " [0.84153676]\n",
      " [0.7777239 ]\n",
      " [0.8453127 ]\n",
      " [0.43914038]\n",
      " [0.8157677 ]\n",
      " [0.69607306]\n",
      " [0.7506527 ]\n",
      " [0.8797591 ]\n",
      " [0.6161146 ]\n",
      " [0.57928807]\n",
      " [0.6924396 ]\n",
      " [0.9099972 ]\n",
      " [0.6971701 ]\n",
      " [0.4398524 ]\n",
      " [0.93259794]\n",
      " [0.64713717]\n",
      " [0.73841447]\n",
      " [0.25977355]\n",
      " [0.4078373 ]\n",
      " [0.1379014 ]\n",
      " [0.29431695]\n",
      " [0.8930609 ]\n",
      " [0.8553163 ]\n",
      " [0.94530225]\n",
      " [0.11859292]\n",
      " [0.53353757]\n",
      " [0.785264  ]\n",
      " [0.6646538 ]\n",
      " [0.8528244 ]\n",
      " [0.41107813]\n",
      " [0.794976  ]\n",
      " [0.6278733 ]\n",
      " [0.6027076 ]\n",
      " [0.70588946]\n",
      " [0.87522197]\n",
      " [0.7657331 ]\n",
      " [0.6386167 ]\n",
      " [0.8704295 ]\n",
      " [0.8809532 ]\n",
      " [0.948012  ]\n",
      " [0.22169697]\n",
      " [0.8036344 ]\n",
      " [0.37591493]\n",
      " [0.42067784]\n",
      " [0.3881559 ]\n",
      " [0.87216043]\n",
      " [0.6758622 ]\n",
      " [0.9201765 ]\n",
      " [0.89417934]\n",
      " [0.5758392 ]\n",
      " [0.14066806]\n",
      " [0.17275825]\n",
      " [0.58952194]\n",
      " [0.7225039 ]\n",
      " [0.65096164]\n",
      " [0.79889596]\n",
      " [0.6162281 ]\n",
      " [0.34211326]\n",
      " [0.23205534]\n",
      " [0.88805425]\n",
      " [0.4235017 ]\n",
      " [0.83674175]\n",
      " [0.8879918 ]\n",
      " [0.699105  ]\n",
      " [0.6472826 ]\n",
      " [0.6008194 ]\n",
      " [0.59748673]\n",
      " [0.68436503]\n",
      " [0.9431385 ]\n",
      " [0.7698594 ]\n",
      " [0.7989595 ]\n",
      " [0.13857019]\n",
      " [0.35320318]\n",
      " [0.90173024]\n",
      " [0.22748056]\n",
      " [0.92886126]\n",
      " [0.31217074]\n",
      " [0.2801682 ]\n",
      " [0.5141376 ]\n",
      " [0.72686696]\n",
      " [0.21982348]\n",
      " [0.751706  ]\n",
      " [0.71645945]\n",
      " [0.77572477]\n",
      " [0.66564   ]\n",
      " [0.13124233]\n",
      " [0.3201778 ]\n",
      " [0.676466  ]\n",
      " [0.4758394 ]\n",
      " [0.9156423 ]\n",
      " [0.9445813 ]\n",
      " [0.70682085]\n",
      " [0.35902548]\n",
      " [0.02779984]\n",
      " [0.7203965 ]\n",
      " [0.3903103 ]\n",
      " [0.5007029 ]\n",
      " [0.9472705 ]\n",
      " [0.6304856 ]\n",
      " [0.94896096]\n",
      " [0.24893278]\n",
      " [0.17110455]\n",
      " [0.28036863]\n",
      " [0.7152521 ]\n",
      " [0.90540594]\n",
      " [0.88402116]\n",
      " [0.6109267 ]\n",
      " [0.60223466]\n",
      " [0.620386  ]\n",
      " [0.13787901]\n",
      " [0.53633904]\n",
      " [0.17699775]\n",
      " [0.5873027 ]\n",
      " [0.87970144]\n",
      " [0.63223076]\n",
      " [0.70110214]\n",
      " [0.9512876 ]\n",
      " [0.81909764]\n",
      " [0.73821515]\n",
      " [0.73901397]\n",
      " [0.7415657 ]\n",
      " [0.8620735 ]\n",
      " [0.36631975]\n",
      " [0.43407017]\n",
      " [0.47796258]\n",
      " [0.8085908 ]\n",
      " [0.6596353 ]\n",
      " [0.6702863 ]\n",
      " [0.7993722 ]\n",
      " [0.3013492 ]\n",
      " [0.47237128]\n",
      " [0.5004597 ]\n",
      " [0.6036682 ]\n",
      " [0.42721245]\n",
      " [0.89372593]\n",
      " [0.73881435]\n",
      " [0.922981  ]\n",
      " [0.54098046]\n",
      " [0.77891374]\n",
      " [0.8023968 ]\n",
      " [0.81748164]\n",
      " [0.61249316]\n",
      " [0.8446343 ]\n",
      " [0.3650545 ]\n",
      " [0.61011976]\n",
      " [0.71352804]\n",
      " [0.36508346]\n",
      " [0.790395  ]\n",
      " [0.30301794]\n",
      " [0.641772  ]\n",
      " [0.9290016 ]\n",
      " [0.79376096]\n",
      " [0.8596209 ]\n",
      " [0.6920742 ]\n",
      " [0.4928022 ]\n",
      " [0.6460284 ]\n",
      " [0.33893016]\n",
      " [0.46320495]\n",
      " [0.6348214 ]\n",
      " [0.639705  ]\n",
      " [0.6611954 ]\n",
      " [0.5436729 ]\n",
      " [0.18844163]\n",
      " [0.6780621 ]\n",
      " [0.9138551 ]\n",
      " [0.58165693]\n",
      " [0.596925  ]\n",
      " [0.79015666]\n",
      " [0.45936087]\n",
      " [0.7142519 ]\n",
      " [0.4689867 ]\n",
      " [0.6922422 ]\n",
      " [0.8849076 ]\n",
      " [0.67787504]\n",
      " [0.70166886]\n",
      " [0.852608  ]\n",
      " [0.5258135 ]\n",
      " [0.86477673]\n",
      " [0.939682  ]\n",
      " [0.30310327]\n",
      " [0.80357987]\n",
      " [0.22983927]\n",
      " [0.7630292 ]\n",
      " [0.817515  ]\n",
      " [0.6926119 ]\n",
      " [0.35103887]\n",
      " [0.7925178 ]\n",
      " [0.7492352 ]\n",
      " [0.74153006]\n",
      " [0.1915384 ]\n",
      " [0.8554505 ]\n",
      " [0.8539486 ]\n",
      " [0.48894668]\n",
      " [0.945192  ]\n",
      " [0.27358142]\n",
      " [0.6720312 ]\n",
      " [0.9460939 ]\n",
      " [0.26914245]\n",
      " [0.42360783]\n",
      " [0.6695834 ]\n",
      " [0.32804602]\n",
      " [0.19664189]\n",
      " [0.8441609 ]\n",
      " [0.90802634]\n",
      " [0.854697  ]\n",
      " [0.6314287 ]\n",
      " [0.6467165 ]\n",
      " [0.60373116]\n",
      " [0.7518921 ]\n",
      " [0.79232013]\n",
      " [0.92823553]\n",
      " [0.7604632 ]\n",
      " [0.78677404]\n",
      " [0.59192926]\n",
      " [0.9359158 ]\n",
      " [0.9372078 ]\n",
      " [0.7321768 ]\n",
      " [0.27180225]\n",
      " [0.654765  ]\n",
      " [0.3564896 ]\n",
      " [0.7581544 ]\n",
      " [0.21157241]\n",
      " [0.24755788]\n",
      " [0.39754605]\n",
      " [0.7173437 ]\n",
      " [0.36522466]\n",
      " [0.58935994]\n",
      " [0.83906615]\n",
      " [0.62991583]\n",
      " [0.8284495 ]\n",
      " [0.9507047 ]\n",
      " [0.7799418 ]\n",
      " [0.07719544]\n",
      " [0.40639415]\n",
      " [0.8368934 ]\n",
      " [0.8626392 ]\n",
      " [0.65712434]\n",
      " [0.28889555]\n",
      " [0.8863195 ]\n",
      " [0.89777446]\n",
      " [0.3463992 ]\n",
      " [0.64334786]\n",
      " [0.8334687 ]\n",
      " [0.8330375 ]\n",
      " [0.83882445]\n",
      " [0.88137364]\n",
      " [0.87205505]\n",
      " [0.9148065 ]\n",
      " [0.6700808 ]\n",
      " [0.66205794]\n",
      " [0.551091  ]\n",
      " [0.8254244 ]\n",
      " [0.8709351 ]\n",
      " [0.2705294 ]\n",
      " [0.7851658 ]\n",
      " [0.8650017 ]\n",
      " [0.3151986 ]\n",
      " [0.55133694]\n",
      " [0.8305297 ]\n",
      " [0.5648696 ]\n",
      " [0.8947294 ]\n",
      " [0.29683566]\n",
      " [0.8262398 ]\n",
      " [0.6473752 ]\n",
      " [0.87667584]\n",
      " [0.3580072 ]\n",
      " [0.7109587 ]\n",
      " [0.69375545]\n",
      " [0.7568823 ]\n",
      " [0.0813227 ]\n",
      " [0.23205325]\n",
      " [0.6884466 ]\n",
      " [0.8242161 ]\n",
      " [0.4886116 ]\n",
      " [0.78110886]\n",
      " [0.4765082 ]\n",
      " [0.39913797]\n",
      " [0.82100517]\n",
      " [0.47768512]\n",
      " [0.89524126]\n",
      " [0.8124903 ]\n",
      " [0.7138164 ]\n",
      " [0.9068881 ]\n",
      " [0.66453   ]\n",
      " [0.7827803 ]\n",
      " [0.37345153]\n",
      " [0.31224185]\n",
      " [0.74492526]\n",
      " [0.44336155]\n",
      " [0.5208213 ]\n",
      " [0.9038869 ]\n",
      " [0.8813911 ]\n",
      " [0.9094621 ]\n",
      " [0.95096457]\n",
      " [0.6767004 ]\n",
      " [0.8655627 ]\n",
      " [0.39268792]\n",
      " [0.39361802]\n",
      " [0.46952534]\n",
      " [0.9300331 ]\n",
      " [0.5985909 ]\n",
      " [0.19726303]\n",
      " [0.92966664]\n",
      " [0.82452095]\n",
      " [0.53163385]\n",
      " [0.7995937 ]\n",
      " [0.02178422]\n",
      " [0.91431034]\n",
      " [0.78676486]\n",
      " [0.75633025]\n",
      " [0.7797084 ]\n",
      " [0.9602601 ]\n",
      " [0.613406  ]\n",
      " [0.7927201 ]\n",
      " [0.6381274 ]\n",
      " [0.8589884 ]\n",
      " [0.19957054]\n",
      " [0.55272394]\n",
      " [0.9087088 ]\n",
      " [0.5641166 ]\n",
      " [0.7086041 ]\n",
      " [0.92873096]\n",
      " [0.83774376]\n",
      " [0.87635434]\n",
      " [0.47195518]\n",
      " [0.75315267]\n",
      " [0.9406934 ]\n",
      " [0.752023  ]\n",
      " [0.6226984 ]\n",
      " [0.3618952 ]\n",
      " [0.4979151 ]\n",
      " [0.54628867]\n",
      " [0.64484596]\n",
      " [0.5214797 ]\n",
      " [0.76895   ]\n",
      " [0.5629578 ]\n",
      " [0.774729  ]\n",
      " [0.821224  ]\n",
      " [0.73186207]\n",
      " [0.6286957 ]\n",
      " [0.50801224]\n",
      " [0.6161816 ]\n",
      " [0.93218005]\n",
      " [0.8633343 ]\n",
      " [0.2677318 ]\n",
      " [0.47598946]\n",
      " [0.49704498]\n",
      " [0.1137079 ]\n",
      " [0.8824491 ]\n",
      " [0.12919632]\n",
      " [0.9024097 ]\n",
      " [0.87962574]\n",
      " [0.83281994]\n",
      " [0.64737594]\n",
      " [0.88646424]\n",
      " [0.32274193]\n",
      " [0.75277424]\n",
      " [0.93869483]\n",
      " [0.2977755 ]\n",
      " [0.4165851 ]\n",
      " [0.87111557]\n",
      " [0.87979925]\n",
      " [0.6445491 ]\n",
      " [0.8007588 ]\n",
      " [0.820104  ]\n",
      " [0.80090606]\n",
      " [0.3192559 ]\n",
      " [0.7336671 ]\n",
      " [0.8759528 ]\n",
      " [0.5721881 ]\n",
      " [0.77797925]\n",
      " [0.68246496]\n",
      " [0.7748291 ]\n",
      " [0.84494853]\n",
      " [0.9284495 ]\n",
      " [0.6283678 ]\n",
      " [0.40007377]\n",
      " [0.75872   ]\n",
      " [0.7285114 ]\n",
      " [0.9650861 ]\n",
      " [0.7822402 ]\n",
      " [0.6928693 ]\n",
      " [0.38781735]\n",
      " [0.7089369 ]\n",
      " [0.9040443 ]\n",
      " [0.9386827 ]\n",
      " [0.89837885]\n",
      " [0.6979885 ]\n",
      " [0.61062384]\n",
      " [0.8009579 ]\n",
      " [0.49984115]\n",
      " [0.81017315]\n",
      " [0.7729541 ]\n",
      " [0.8775407 ]\n",
      " [0.60753584]\n",
      " [0.6979289 ]\n",
      " [0.8480623 ]\n",
      " [0.50266767]\n",
      " [0.53485245]\n",
      " [0.6610211 ]\n",
      " [0.73299944]\n",
      " [0.6385366 ]\n",
      " [0.92238176]\n",
      " [0.9254356 ]\n",
      " [0.23066479]\n",
      " [0.14782417]\n",
      " [0.77836466]\n",
      " [0.53121936]\n",
      " [0.2467286 ]\n",
      " [0.8265269 ]\n",
      " [0.9006588 ]\n",
      " [0.66984594]\n",
      " [0.9343132 ]\n",
      " [0.91945696]\n",
      " [0.75093347]\n",
      " [0.846567  ]\n",
      " [0.6636043 ]\n",
      " [0.6005768 ]\n",
      " [0.74917495]\n",
      " [0.6028411 ]\n",
      " [0.14005637]\n",
      " [0.9088658 ]\n",
      " [0.87197864]\n",
      " [0.7037835 ]\n",
      " [0.9070275 ]\n",
      " [0.8697318 ]\n",
      " [0.88113105]\n",
      " [0.5948857 ]\n",
      " [0.7058871 ]\n",
      " [0.8761473 ]\n",
      " [0.702897  ]\n",
      " [0.8513341 ]\n",
      " [0.9165032 ]\n",
      " [0.5854051 ]\n",
      " [0.80146384]\n",
      " [0.79189646]\n",
      " [0.5509083 ]\n",
      " [0.50143456]\n",
      " [0.08161414]\n",
      " [0.28687462]\n",
      " [0.8183676 ]\n",
      " [0.6202601 ]\n",
      " [0.68615675]\n",
      " [0.52148336]\n",
      " [0.9269684 ]\n",
      " [0.44325155]\n",
      " [0.7866597 ]\n",
      " [0.26438633]\n",
      " [0.87165445]\n",
      " [0.3585294 ]\n",
      " [0.8007282 ]\n",
      " [0.5705955 ]\n",
      " [0.8185915 ]\n",
      " [0.5701346 ]\n",
      " [0.2610221 ]\n",
      " [0.80574906]\n",
      " [0.9212425 ]\n",
      " [0.40310335]\n",
      " [0.9058887 ]\n",
      " [0.871122  ]\n",
      " [0.8278078 ]\n",
      " [0.8078148 ]\n",
      " [0.42055866]\n",
      " [0.30597222]\n",
      " [0.67866087]\n",
      " [0.18904224]\n",
      " [0.94046056]\n",
      " [0.39347947]\n",
      " [0.9230144 ]\n",
      " [0.8797076 ]\n",
      " [0.4199416 ]\n",
      " [0.2160351 ]\n",
      " [0.6854111 ]\n",
      " [0.4467407 ]\n",
      " [0.81949717]\n",
      " [0.71135724]\n",
      " [0.9766583 ]\n",
      " [0.49361563]\n",
      " [0.63086724]\n",
      " [0.80758   ]\n",
      " [0.7451041 ]\n",
      " [0.07227561]\n",
      " [0.77037096]\n",
      " [0.78722847]\n",
      " [0.85695755]\n",
      " [0.5928472 ]\n",
      " [0.45006526]\n",
      " [0.60811055]\n",
      " [0.8908487 ]\n",
      " [0.5845325 ]\n",
      " [0.7932035 ]\n",
      " [0.79318905]\n",
      " [0.87026346]\n",
      " [0.77783763]\n",
      " [0.5465314 ]\n",
      " [0.77334285]\n",
      " [0.90169096]\n",
      " [0.714     ]\n",
      " [0.9541085 ]\n",
      " [0.79897064]\n",
      " [0.62400687]\n",
      " [0.4779551 ]\n",
      " [0.799854  ]\n",
      " [0.8350437 ]\n",
      " [0.52036965]\n",
      " [0.64866376]\n",
      " [0.2548322 ]\n",
      " [0.56802845]\n",
      " [0.80403125]\n",
      " [0.9428852 ]\n",
      " [0.83740956]\n",
      " [0.74328846]\n",
      " [0.72086376]\n",
      " [0.8969884 ]\n",
      " [0.5216268 ]\n",
      " [0.9226314 ]\n",
      " [0.55577886]\n",
      " [0.8337263 ]\n",
      " [0.30164576]\n",
      " [0.09063858]\n",
      " [0.32616878]\n",
      " [0.36176047]\n",
      " [0.6907465 ]\n",
      " [0.8399777 ]\n",
      " [0.59088063]\n",
      " [0.73178077]\n",
      " [0.8012066 ]\n",
      " [0.51672214]\n",
      " [0.37486812]\n",
      " [0.8824762 ]\n",
      " [0.90409863]\n",
      " [0.49567568]\n",
      " [0.6445349 ]\n",
      " [0.18635225]\n",
      " [0.36835158]\n",
      " [0.73928225]\n",
      " [0.70828897]\n",
      " [0.8874692 ]\n",
      " [0.97395396]\n",
      " [0.24407873]\n",
      " [0.7559597 ]\n",
      " [0.60264957]\n",
      " [0.412533  ]\n",
      " [0.7302375 ]\n",
      " [0.7021316 ]\n",
      " [0.8860748 ]\n",
      " [0.7026828 ]\n",
      " [0.5408505 ]\n",
      " [0.6023426 ]\n",
      " [0.19653344]\n",
      " [0.6904205 ]\n",
      " [0.5387346 ]\n",
      " [0.893227  ]\n",
      " [0.5864215 ]\n",
      " [0.58895767]\n",
      " [0.7680435 ]\n",
      " [0.7485901 ]\n",
      " [0.47902453]\n",
      " [0.7680899 ]\n",
      " [0.6186183 ]\n",
      " [0.32383102]\n",
      " [0.6076526 ]\n",
      " [0.8904605 ]\n",
      " [0.8557354 ]\n",
      " [0.58092564]\n",
      " [0.7931185 ]\n",
      " [0.29612774]\n",
      " [0.8487417 ]\n",
      " [0.6114426 ]\n",
      " [0.7562415 ]\n",
      " [0.42934278]\n",
      " [0.62562895]\n",
      " [0.8278314 ]\n",
      " [0.16056871]\n",
      " [0.29422316]\n",
      " [0.76999336]\n",
      " [0.81526726]\n",
      " [0.7907809 ]\n",
      " [0.9065112 ]\n",
      " [0.79228914]\n",
      " [0.6920925 ]\n",
      " [0.7595737 ]\n",
      " [0.772054  ]\n",
      " [0.7166187 ]\n",
      " [0.80744374]\n",
      " [0.51067567]\n",
      " [0.43409863]\n",
      " [0.8745171 ]\n",
      " [0.8001001 ]\n",
      " [0.6428945 ]\n",
      " [0.3399259 ]\n",
      " [0.8728409 ]\n",
      " [0.7723805 ]\n",
      " [0.8353516 ]\n",
      " [0.65519303]\n",
      " [0.8738025 ]\n",
      " [0.8658458 ]\n",
      " [0.7776918 ]\n",
      " [0.4338878 ]\n",
      " [0.8870811 ]\n",
      " [0.9114084 ]\n",
      " [0.32181153]\n",
      " [0.16825002]\n",
      " [0.71784896]\n",
      " [0.47934446]\n",
      " [0.80839145]\n",
      " [0.35433513]\n",
      " [0.4099325 ]\n",
      " [0.39260605]\n",
      " [0.79843915]\n",
      " [0.86093646]\n",
      " [0.17698795]\n",
      " [0.37649366]\n",
      " [0.6054129 ]\n",
      " [0.50533026]\n",
      " [0.51275516]\n",
      " [0.7998054 ]\n",
      " [0.16670048]\n",
      " [0.9075521 ]\n",
      " [0.2142213 ]\n",
      " [0.8227194 ]\n",
      " [0.71084   ]\n",
      " [0.7442361 ]\n",
      " [0.8275754 ]\n",
      " [0.683654  ]\n",
      " [0.892762  ]] \n",
      "Correct(Y):  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  0.76811594\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis>0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    feed = {X: x_data, Y: y_data}\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict=feed)\n",
    "        if step %200 ==0:\n",
    "            print(step, sess.run(cost, feed_dict = feed))\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict=feed)\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect(Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab 06 Softmax Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.8480997\n",
      "200 0.54636586\n",
      "400 0.45340627\n",
      "600 0.38012353\n",
      "800 0.31055906\n",
      "1000 0.24178606\n",
      "1200 0.21589087\n",
      "1400 0.19710973\n",
      "1600 0.18123353\n",
      "1800 0.16764417\n",
      "2000 0.15588842\n",
      "--------------\n",
      "[[9.0882536e-03 9.9090040e-01 1.1342816e-05]] [1]\n",
      "--------------\n",
      "[[0.8041279  0.16546802 0.0304041 ]] [0]\n",
      "--------------\n",
      "[[1.4274465e-08 3.5179307e-04 9.9964821e-01]] [2]\n",
      "--------------\n",
      "[[9.0882536e-03 9.9090040e-01 1.1342816e-05]\n",
      " [8.0412799e-01 1.6546790e-01 3.0404063e-02]\n",
      " [1.4274465e-08 3.5179307e-04 9.9964821e-01]] [1 0 2]\n"
     ]
    }
   ],
   "source": [
    "x_data= [[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7]]\n",
    "y_data = [[0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], [0,1,0], [1,0,0], [1,0,0]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W)+b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict= {X:x_data, Y:y_data})\n",
    "        if step%200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = {X: x_data, Y: y_data}))\n",
    "    print('--------------')\n",
    "    # Testing & One-hot encoding\n",
    "    a = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9]]})\n",
    "    print(a, sess.run(tf.argmax(a, 1)))\n",
    "\n",
    "    print('--------------')\n",
    "    b = sess.run(hypothesis, feed_dict={X: [[1, 3, 4, 3]]})\n",
    "    print(b, sess.run(tf.argmax(b, 1)))\n",
    "\n",
    "    print('--------------')\n",
    "    c = sess.run(hypothesis, feed_dict={X: [[1, 1, 0, 1]]})\n",
    "    print(c, sess.run(tf.argmax(c, 1)))\n",
    "\n",
    "    print('--------------')\n",
    "    all = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9], [1, 3, 4, 3], [1, 1, 0, 1]]})\n",
    "    print(all, sess.run(tf.argmax(all, 1)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
